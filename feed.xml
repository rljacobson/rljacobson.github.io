<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2020-07-01T13:33:07-04:00</updated><id>/</id><title type="html">After Math</title><subtitle>A blog by Robert Jacobson.</subtitle><author><name>Robert Jacobson</name></author><entry><title type="html">Bayes’ Theorem and the Deathly Hallows</title><link href="/Bayes-Theorem" rel="alternate" type="text/html" title="Bayes' Theorem and the Deathly Hallows" /><published>2020-07-01T11:00:00-04:00</published><updated>2020-07-01T11:00:00-04:00</updated><id>/Bayes-Theorem</id><content type="html" xml:base="/Bayes-Theorem">&lt;p&gt;This article is an expanded version of the math part of &lt;a href=&quot;https://medium.com/@arhyne/covid-19-population-testing-vs-thoughts-and-prayers-454e64946dde&quot;&gt;an article I
   cowrote with marine biologist Dr. Andrew Rhyne about how &lt;strong&gt;many well-meaning public health professionals have misinterpreted the math
    behind test
    efficiency, Bayes’ Theorem. This misinterpretation has lead to dangerous public policy positions.&lt;/strong&gt;&lt;/a&gt; Anyone with a math allergy is invited to read that article instead.&lt;/p&gt;

&lt;p&gt;I and Dr. Andrew Rhyne, marine biologist and my 
&lt;a href=&quot;http://natureintelligence.trade/&quot;&gt;longtime collaborator in fighting wildlife crime&lt;/a&gt;, have
 spent a lot of time in the last several months working on how best to fight the
 COVID-19 pandemic, especially in college communities like
  our own Roger Williams University.&lt;/p&gt;

&lt;h2 id=&quot;how-understanding-bayes-theorem-is-crucial-in-informing-health-policies&quot;&gt;How understanding Bayes’ Theorem is crucial in informing health policies&lt;/h2&gt;

&lt;p&gt;&lt;img style=&quot;width:auto;&quot; src=&quot;assets/images/posts/Covid19Testing/VennDiagram.png&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Imagine a Venn diagram of intellectual ideas with three overlapping circles as depicted above. The first orange
 circle represents those ideas that are important for the well-being, smooth functioning, and progression of human
  society. In this circle, we find the germ theory of disease, the moral imperative of the Golden Rule, and basic arithmetic. The second blue circle represents ideas that are confusing or subtle. The Hegelian dialectic lives here alongside every book with the word semiotics in the title, and the Paradox of Indoor Ornithology, which claims that the sight of a green apple is evidence supporting the notion that all ravens are black ravens.&lt;sup id=&quot;fnref:ravens&quot;&gt;&lt;a href=&quot;#fn:ravens&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; If you just said, “What?,” I want to point out that that’s the point: these are difficult, confusing ideas. Finally, we have the circle of ideas that are just too easy to believe one understands when one actually does not. These are ideas that, whether or not they appear simple, have the peculiar ability to lure us into a completely unfounded confidence in our understanding of them. Clearly this circle contains virtually all public political discourse, for example, but it also contains some surprises: Robert Frost’s “&lt;em&gt;Stopping by Woods on a Snowy Evening&lt;/em&gt;,” the dangers of quicksand, leprosy, and the inventor of peanut butter, to name a few. You think you know, but google it.&lt;/p&gt;

&lt;p&gt;Frightening is the overlapping intersection of these three circles. Here are challenging ideas that are important for human society that we often get wrong while confidently believing we understand. &lt;em&gt;Bayes’ Theorem is one of these ideas.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-basics-of-bayes-theorem&quot;&gt;The Basics of Bayes’ Theorem&lt;/h2&gt;

&lt;p&gt;It’s not that Bayes’ Theorem is widely known—it does have “theorem” in its name, after all. But when it is known, it is often misinterpreted or misapplied. Despite mathematical notation that makes it look like an alien language, Bayes’ Theorem is actually quite short and simple:&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\displaystyle P(A\mid B) = \frac{P(B \mid A) \times P(A)}{P(B)}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;This formula expresses a relationship between four probabilities. It’s best explained with a concrete example, and the subject of this article, testing for disease, is a classic. If we test somebody for, say, COVID-19, then there are four possible scenarios:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Person actually has COVID-19&lt;/th&gt;
      &lt;th&gt;Person does not have COVID-19&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Test result is positive&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;true positive&lt;/td&gt;
      &lt;td&gt;false positive&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Test result is negative&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;false negative&lt;/td&gt;
      &lt;td&gt;true negative&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;A word of warning: It is &lt;em&gt;very easy&lt;/em&gt; to mix up these terms. Just keep referring back to this table whenever you need to.&lt;/p&gt;

&lt;p&gt;The first thing to understand is this: The probability of having COVID-19 &lt;em&gt;given&lt;/em&gt; that you already know the test came out positive, which we will denote by $P(cov\mid pos)$, is a &lt;em&gt;different&lt;/em&gt; probability from the probability of the test coming out positive &lt;em&gt;given&lt;/em&gt; you have COVID-19, which we likewise denote by  $P(pos\mid cov)$. The difference, of course, is what information you already know. The question, “If an animal is in the chicken coup, what’s the probability that it is a chicken?,” $P(coup \mid chicken)$ in our notation, is a different question from, “If the animal is a chicken, what is the probability that it is in the coup?,” $P(chicken\mid coup)$. It could be that my chickens are indoor chickens that never leave the coup, so $P(coup \mid chicken)=100\%$, but I also keep an equal number of turkeys in the coup, so $P(chicken \mid coup) = 50\%$.&lt;sup id=&quot;fnref:turkeys&quot;&gt;&lt;a href=&quot;#fn:turkeys&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;You are now fluent in the alien language that makes up the mathematical notation of Bayes’ Theorem. The power of Bayes’ Theorem is that we can convert from $P(chicken \mid coup)$ into $P(coup\mid chicken)$ using the unconditional probabilities of an animal being a chicken regardless of location, $P(chicken)$, and the probability of an animal being in the coup regardless of species, $P(coup)$. With COVID-19 testing, we can compute the probability that you are infected with COVID-19 given that your test result is positive using knowledge of the probability that you will test positive given that you really are infected:&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\displaystyle P(cov\mid pos) = \frac{P(pos \mid cov) \times P(pos)}{P(cov)}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;This mathematical trick allows us to determine the relationships between the four scenarios in the table above.&lt;/p&gt;

&lt;h2 id=&quot;the-importance-of-bayes-theorem&quot;&gt;The Importance of Bayes’ Theorem&lt;/h2&gt;

&lt;p&gt;It should be obvious that understanding the performance of tests for disease and of drugs with which to treat them is paramount for the prevention and treatment of disease from the individual level to the level of worldwide populations.&lt;/p&gt;

&lt;p&gt;As we form policies about testing people for COVID-19, we need to answer these questions: How should the knowledge we get out of Bayes’ Theorem influence our testing strategy for monitoring the population for COVID-19? What policies would be the best use of our limited resources?&lt;/p&gt;

&lt;h2 id=&quot;the-paradox-of-bayes-theorem&quot;&gt;The Paradox of Bayes’ Theorem&lt;/h2&gt;

&lt;p&gt;What could be so subtle about a simple formula with just four quantities and two arithmetic operations? In short, interpretation. Here is a classic homework problem described by mathematician Chris Wiggins&lt;sup id=&quot;fnref:wiggins&quot;&gt;&lt;a href=&quot;#fn:wiggins&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A patient goes to see a doctor. The doctor performs a test with 99 percent reliability—that is, 99 percent of people who are sick test positive and 99 percent of the healthy people test negative. The doctor knows that only one percent of the people in the country are sick. Now the question is: if the patient tests positive, what are the chances the patient is sick?&lt;/p&gt;

  &lt;p&gt;The intuitive answer is 99 percent, but the correct answer is 50 percent….&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Even with “good” tests, testing positive does not necessarily mean you “probably” have the disease! For this example, the surprising result is because the disease is very rare in the population. When it comes to testing for diseases, the punchline is: &lt;em&gt;There is a higher proportion of false positives relative to true positives when the prevalence of a disease is very low.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-deadly-misunderstanding-of-bayes-theorem&quot;&gt;The Deadly Misunderstanding of Bayes’ Theorem&lt;/h2&gt;

&lt;h3 id=&quot;false-positives&quot;&gt;False Positives&lt;/h3&gt;

&lt;p&gt;That last sentence is worth repeating:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;There is a higher proportion of false positives relative to true positives when the prevalence of a disease is very low.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;False positives come with “costs”. If people who test positive but are in reality not infected have to self-quarantine, they could experience a major disruption to their lives, including to their financial and mental health. Citing Bayes’ Theorem, many experts conclude that because COVID-19 is such a low-incidence disease, the cost of whole population testing outweighs the benefits. A logician might structure this argument as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The prevalence of COVID-19 is low, perhaps less than 1% in the United States.&lt;/li&gt;
  &lt;li&gt;Since the prevalence of the disease is very low, the proportion of false positives to true positives will be high for any given test.&lt;/li&gt;
  &lt;li&gt;The social and economic cost of false positives is high.&lt;/li&gt;
  &lt;li&gt;Therefore, the cost of large scale testing swamps any possible benefit.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;This is a dangerously incorrect mathematical interpretation.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Consider a 99% reliable test as in the classic example above. Suppose we test a town with a population of 10,000 people. If 0.1% of people in town (that’s 1 in 1000) are infected, then 10 people have COVID-19, and our test detects all 10 of them 99 times out of 100 (on average). Meanwhile, the test incorrectly labels 1% of the 9990 remaining people (again, on average), which is about 100 people, as positive.&lt;/p&gt;

&lt;p&gt;Will we get significantly fewer false positives if the infection rate is higher, as some experts suggest? Let’s instead suppose that 1% of the people are actually infected—that’s 100 infected people, 10 times more than we thought. Then the test correctly labels 99 of the 100 infected people on average. Of the remaining 9900 covid-free people, 99 people are incorrectly labeled as positive by the test. There are fewer false positives, yes, but fewer only by one person.&lt;/p&gt;

&lt;p&gt;The mistake is to think that the quality of testing depends on the prevalence of disease. It doesn’t. The test will be exactly the same regardless of prevalence, because its false positive rate is not affected by prevalence. The test could not possibly be influenced by the state of the population outside of the testing lab.&lt;/p&gt;

&lt;p&gt;On the other hand, our testing policies must be informed by the state of the population. A significantly lower prevalence &lt;em&gt;does not&lt;/em&gt; result in &lt;em&gt;significantly more&lt;/em&gt; false positives as some experts have claimed, and so we shouldn’t care at all that 50% versus 9% of the people who tested positive are actually infected—the “cost” we pay as a population for those false positives is virtually the same as it would be with a much higher rate of infection. Yet the benefit is exponential: We catch infections much sooner, &lt;em&gt;before&lt;/em&gt; they have a chance to take root.&lt;/p&gt;
&lt;figure&gt;
&lt;img alt=&quot;Thoughts and Prayers vs. Aggressive Population Testing.&quot; src=&quot;assets/images/posts/Covid19Testing/ExponentialGraph.png&quot; style=&quot;width:75%&quot; /&gt;
&lt;figcaption style=&quot;font-size: small; font-weight: bold; text-align: center&quot;&gt;Thoughts and Prayers vs. Aggressive Population Testing.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;We want nobody in the population to be infected, and if nobody is infected, then the only way for a test to turn out positive is if the test is wrong—a &lt;em&gt;false&lt;/em&gt; positive. In other words, we want &lt;em&gt;every&lt;/em&gt; positive test result to be a &lt;em&gt;false&lt;/em&gt; positive—and to keep it that way. Choosing not to test the population at large because the prevalence of disease is low is the equivalent of deciding that you don’t need to take your medication anymore because it is working. The reason you are healthy is &lt;em&gt;because&lt;/em&gt; it is working! &lt;em&gt;Many&lt;/em&gt; &lt;em&gt;public health&lt;/em&gt; &lt;em&gt;specialists&lt;/em&gt; &lt;em&gt;are advising schools and employers based on exactly this backwards reasoning.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;false-negatives&quot;&gt;False Negatives&lt;/h3&gt;

&lt;p&gt;Some have argued that we should be concerned instead about false negatives. Suppose, for example, that a test is only capable of identifying an infected sample 50% of the time. That means roughly that every time the population is tested, half of the infected individuals are identified and removed (via quarantine). If removing half of all infected individuals from a college campus sounds like an obviously good idea to you, that’s is because it is. Simple arithmetic shows whole population testing — especially repeated whole population testing — reduces the number of infected individuals in the population. (Sophisticated models do as well: See &lt;a href=&quot;https://larremorelab.github.io/covid-calculator3&quot;&gt;Larremore et al.&lt;/a&gt;; &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S1551741120305313&quot;&gt;Dawoud, RSAP.&lt;/a&gt;)&lt;/p&gt;
&lt;figure&gt;
&lt;img alt=&quot;Sample simulation trajectories from fully mixed model demonstrating the effectiveness of whole population testing.&quot; src=&quot;assets/images/posts/Covid19Testing/LarremoreModel.png&quot; style=&quot;width:auto&quot; /&gt;
&lt;figcaption style=&quot;font-size: small; font-weight: bold; text-align: center&quot;&gt;
Sample simulation trajectories from fully mixed model demonstrating the effectiveness of whole population testing. Notice the scale of the $y$-axis. (Figure S1 of 
&lt;a href=&quot;https://www.medrxiv.org/content/10.1101/2020.06.22.20136309v2&quot;&gt;Larremore et al. preprint&lt;/a&gt;)
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;And yet some health experts like Dr. Tom Jeanne, the deputy epidemiologist for Oregon, justifies his guidance to not employ whole population testing based on the rate of false negatives: “A negative result does not meaningfully increase confidence that a person is not infected,” Jeanne said. “And just as importantly, a negative result does not mean that a person has any period of protection when they are not or cannot be infected” (&lt;a href=&quot;https://www.insidehighered.com/news/2020/06/22/differing-views-states-consider-whether-colleges-should-test-all-students-covid-19&quot;&gt;Murakami, InsideHigherEd&lt;/a&gt;). But our inability to certify an individual as disease free with a high degree of confidence is immaterial. Our goal, rather, is to reduce the rate of infection to zero or near zero and then keep it that way.&lt;/p&gt;

&lt;p&gt;The discussion so far is based on the premise that tests for COVID-19 have a nonzero false positive rate. Current
 tests for COVID-19 use a diagnostic technique called qPCR to detect the presence of three distinct genes, a control and two carried by the coronavirus that causes COVID-19.&lt;sup id=&quot;fnref:qpcr&quot;&gt;&lt;a href=&quot;#fn:qpcr&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; In essence, the test makes copies of these genes, if they are present, “amplifies” their presence in the sample, and quantifies the amount of the original gene by measuring this amplification. For this discussion, our only interest is in the presence or absence of the gene. The probability of detecting these genes in people that are notor were not infected by nCOV-SARS-2 is virtually zero. Thus, if the gene is detectable after amplification, it must have been present in the original sample, and the person that sample came from must therefore be infected by the virus. If a gene were somehow constructed by cosmic coincidence, it is possible that the gene would be amplified and detected by the test. But remember, two distinct genes are detected, so a false positive requires not one but two separate cosmic coincidences to occur simultaneously. It is exceedingly rare to have a false positive with the PCR methods developed for this virus. &lt;em&gt;None of the FDA approved tests have false positives.&lt;/em&gt; (&lt;a href=&quot;https://www.fda.gov/emergency-preparedness-and-response/mcm-legal-regulatory-and-policy-framework/emergency-use-authorization%23LDTs&quot;&gt;FDA&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;On the other hand, false negatives &lt;em&gt;are&lt;/em&gt; possible. For qPCR methods, a false negative occurs when the viral load, that is, the number of viruses in the sample, starts out too low to be amplified sufficiently to be detected (&lt;a href=&quot;https://asm.org/Articles/2020/April/False-Negatives-and-Reinfections-the-Challenges-of&quot;&gt;Prinzi&lt;/a&gt;&lt;a href=&quot;https://asm.org/Articles/2020/April/False-Negatives-and-Reinfections-the-Challenges-of&quot;&gt;, ASM&lt;/a&gt;). In the course of a COVID-19 infection, there are two time periods during which the viral load is very low: when the infection has only barely begun, and when the virus has been almost completely wiped out by the body’s immune system. Early in the infection (&lt;a href=&quot;https://www.acpjournals.org/doi/10.7326/M20-1495&quot;&gt;Kucirka et al, AIM&lt;/a&gt;) is the period with the highest likelihood that an infected person will transmit the virus to others. This is also the easiest point in the progression of infection to detect the virus. Thus, false negative rates are tied to infection potential: the higher the potential for spreading the infection, the lower the false negative rate, and vice versa. This situation is exactly why testing populations repeatedly are worthy causes.&lt;/p&gt;

&lt;p&gt;What does Dr. Jeanne conclude from this? That because false negative rates are high, the results likely will be wrong, and thus it doesn’t make sense to use tests on asymptomatic people (&lt;a href=&quot;https://www.insidehighered.com/news/2020/06/22/differing-views-states-consider-whether-colleges-should-test-all-students-covid-19&quot;&gt;Murakami, InsideHigherEd&lt;/a&gt;). This is not what a high false negative rate means. A test with a high false negative rate might also have an extremely high true positive rate, which is precisely the situation with qPCR tests for COVID-19. Indeed, if almost nobody has a disease, then a test that always gives a negative result no matter what would be correct &lt;em&gt;the vast majority of the time&lt;/em&gt;. It simply is not the appropriate measure by which to judge a test in this context.&lt;/p&gt;

&lt;h2 id=&quot;the-deadly-misapplication-of-bayes-theorem&quot;&gt;The Deadly Misapplication of Bayes’ Theorem&lt;/h2&gt;

&lt;p&gt;Moreover, when we say the false negative rate is &lt;em&gt;high&lt;/em&gt;, we implicitly mean that it is high &lt;em&gt;relative to some other thing&lt;/em&gt; and &lt;em&gt;for a specific purpose&lt;/em&gt;. If a person is tested every 3 days, and the false negative rate is 70%, then the probability that the person will test positive before or on day nine is 76%. Now, a false negative rate of 70% is very high relative to other tests for other diseases, and for the purpose of testing a person a single time to certify that person as free of disease, the test would be all but useless. But in the context of whole population testing, even a false negative rate as “bad” as 70% is actually pretty good.&lt;/p&gt;

&lt;p&gt;This misinterpretation of the significance of Bayes’ Theorem and of false positives and false negatives in particular is not isolated to just one or two public health specialists. I have collected in the table below just a small sampling of different public health authorities that are making this same mistake.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Public health professionals arguing against mass scale testing.&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;Person / Group&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Reason for not deploying population scale testing.&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Dr. Tom Jeanne, the deputy epidemiologist for &lt;a href=&quot;http://www.oregon.gov/highered/about/Documents/News-Updates/OHA-HECC-higher-education-health-standards-covid-FINAL.pdf&quot;&gt;Oregon&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;“’A negative result does not meaningfully increase confidence that a person is not infected,’ Jeanne said. ’And just as importantly, a negative result does not mean that a person has any period of protection when they are not or cannot be infected.’&quot;And because the state has only so many tests, he said it doesn’t make sense to use them on asymptomatic people when the results likely will be wrong.”&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Michael T. Osterholm, PhD, MPH of University of Minnesota, &lt;a href=&quot;https://www.cidrap.umn.edu/covid-19/covid-19-cidrap-viewpoint&quot;&gt;CIDRAP&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;“Universal testing in hospital settings (not recommended). Universal testing of all patients at the time of admission is of limited value in areas with low prevalence of infection (particularly in the absence of a known exposure) because of the high likelihood of false-positive tests. The lower predictive value of a positive test in this setting makes interpretation of the test result difficult.”&lt;br /&gt;&lt;br /&gt;“Workplace testing (not recommended except in certain circumstances). In most situations, workplace testing will not be of value… Owing to uncertainties in test performance in asymptomatic individuals because of low prevalence of infection in the population, the meaning of a positive or negative test result in this situation is not clear.”&lt;br /&gt;&lt;br /&gt;“Widespread community-based testing (not recommended). Again, in low-prevalence settings, widespread community testing does not offer a public health benefit because of the varying positive and negative predictive value of the test results.”&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acha.org/documents/Resources/COVID_19/COVID-19_Testing_June-3-2020.pdf&quot;&gt;American College Health Association&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;“The overall prevalence of COVID in a healthy young adult population is likely to be very low, and probably less than 1%. At this prevalence level, the positive and negative predictive values of most screening tests would be unreliable unless the test used has both extremely high sensitivity and specificity. Many tests available today do not meet that standard.”&lt;br /&gt;“Screening large numbers (thousands) of students will likely produce no substantial public health benefit, and at very high cost.”&lt;br /&gt;Response to our email expressing concern about their approach: “Thank you for reaching out and providing your thoughts. Our brief aligns with current CDC testing recommendations.”&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://covid.risd.edu/faq/&quot;&gt;Rhode Island School of Design&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;“Based on our research, as well as consultation with &lt;a href=&quot;https://keelingassociates.com/&quot;&gt;Keeling and Associates,&lt;/a&gt; we recommend that RISD focus on the use of diagnostic testing, initiated by symptomatology and/or contact tracing, supported by strict use of quarantine and isolation. Mass testing of asymptomatic people has been proposed by several schools, however we have found that such testing does not have high scientific value, because it provides only a quick snapshot of a current condition, which could change within hours. We also do not recommend surveillance testing, which samples the population to track the presence of the virus, because the rates of false negative/positive results for low-prevalence groups may approach the population disease incidence (~1%).”&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;the-mathematicians-stone&quot;&gt;The Mathematician’s Stone&lt;/h2&gt;

&lt;p&gt;Some widespread claims about population testing are likely to be true. For example, several scientists and public health specialists have pointed out that random population sampling is unlikely to make a significant impact on public health. This claim is backed by strong scientific evidence. There is also near universal agreement that serology (antibody) tests, or any other tests currently available for past or present nCOV-SARS-2 infection, should not be used to clear someone as healthy and therefore safe to join a group. Since these conversations necessarily use a lot of technical language—serology tests, random sampling—it is all too easy for nonspecialists to hear one thing and understand another. It matters a great deal how scientists talk about these technical topics. Scientists need to anticipate sources of confusion, like the difference between sensitivity and specificity, or false positives and false negatives, or random sampling and whole population testing.&lt;/p&gt;

&lt;p&gt;It is possible that I am grossly misinformed regarding the characteristics of qPCR testing for COVID-19, or that I am
 wrong in thinking most people have significant misconceptions about leprosy. But with mathematics, nobody needs to trust what I say is true on my authority as a mathematician. Anyone with sufficient mathematical training can see for themselves. To make it easier for nonscientists to do this kind of verification, I have built an online tool that anyone can use to compute outcomes of interest based on estimates of a test’s performance characteristics that can be adjusted with a slider. The source code is also available on GitHub so that anyone who finds a mistake in the code can report the error or even submit a fix.&lt;/p&gt;
&lt;figure&gt;
&lt;a href=&quot;https://www.robertjacobson.dev/BayesTesting/BayesTesting.html&quot;&gt;
&lt;img alt=&quot;Online probability calculator&quot; src=&quot;assets/images/posts/Covid19Testing/Screenshot.png&quot; style=&quot;width:auto; border: 1px solid #2e2e2e&quot; /&gt;
&lt;/a&gt;
&lt;figcaption style=&quot;font-size: small; font-weight: bold; text-align: center&quot;&gt;
The tool is live at this address: &lt;a href=&quot;https://www.robertjacobson.dev/BayesTesting/BayesTesting.html&quot;&gt;https://www.robertjacobson.dev/BayesTesting/BayesTesting.html&lt;/a&gt;.
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;I want to be very clear about what I am criticizing in the work of the scientists I have pointed out by name or description. In the case of Oregon’s deputy epidemiology Dr. Tom Jeanne, for instance, it may be the case that Dr. Jeane is right that wide-scale testing is not the right thing for Oregon at this time. There are many factors to consider in making that determination, including test kit availability, test processing capacity, and funding, and it is likely that Dr. Jeane has carefully weighed all of these factors. However, his claim that a high false negative rate means that test results will likely be incorrect or that they make wide-scale testing of little use &lt;em&gt;is wrong as a matter of arithmetic&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;but-what-if&quot;&gt;But What If…?&lt;/h2&gt;

&lt;p&gt;A variety of justifications have been proposed for not implementing whole-population testing. Suppose that the only tests we have access to are not as good as the qPCR methods have been described above.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;Problem&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Remedy&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The sensitivity (true positive rate) of the test is low, resulting in many false negatives&lt;/td&gt;
      &lt;td&gt;Test often and reduce the dilution of the samples at collection.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;The specificity (true negative rate) of the test is low, resulting in many false positives.&lt;/td&gt;
      &lt;td&gt;Re-test samples that test positive, preferably with a more accurate test. If the population is tested frequently at regular intervals, say, every three days, a person who tests positive might only be asked to quarantine until the next test returns negative. Since the entire population is regularly tested, contact tracing may not be necessary. In some limited circumstances, it might be reasonable only to ask someone who tests positive to follow more aggressive prevention and social distancing practices instead of absolute quarantine until they can be retested.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;The prevalence (infection rate) of the disease is extremely low or zero.&lt;/td&gt;
      &lt;td&gt;This is the goal and is not a problem. Keep testing to keep it this way.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We do not have the test processing capacity or number of tests or financial resources necessary to test everybody in the population.&lt;/td&gt;
      &lt;td&gt;Several reports have demonstrated sample pooling as effective in the context of population monitoring for COVID-19. Sample pooling can increase testing capacity by an order of magnitude and reduce costs.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Quarantining and contact tracing are too disruptive or costly or distressing to implement for someone who is a false positive (healthy but tests positive).&lt;/td&gt;
      &lt;td&gt;If you are regularly testing the entire population, there is less need to do contact tracing, because you are already testing the contacts regularly. Reduce false positives by retesting samples that test positive, preferably with a more accurate test. People who test positive can also be tested again after a few days, increasing confidence in the test result.People that are isolated because of contacts with positive people can be tested negative and return to their lives rather than sitting in isolation for two weeks.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Even with mitigation strategies, the test processing capacity is not sufficient to test everyone.&lt;/td&gt;
      &lt;td&gt;Test as many people as you have capacity for on a schedule that will eventually test everyone given enough time. Prioritize the processing of tests of clinical importance, skipping them to the front of the line.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Among the greatest concerns of public health officials regarding whole population testing are the availability and cost of tests and the available capacity to process the tests. At the same time, the benefit of whole population testing is enormous. Resource usage may be a limiting factor in some regions, but sample pooling can potentially magnify the capacity of those resources by an order of magnitude. Performing and processing 2,500 tests a day might be out of reach for a single institution, but 300 or fewer tests required by sample pooling might be feasible, allowing the institution to test everyone on a regular schedule. Over time, test processing capacity is likely to increase (&lt;a href=&quot;http://www.mhtc.org/wp-content/uploads/2020/05/2020.5.22-MHTC-Main-Deck-vFinal.pdf&quot;&gt;MA High Technology Council, The War on COVID-19: Reducing Rt Deep Dives&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&quot;when-not-to-use-whole-population-testing-and-when-to-stop-testing&quot;&gt;When not to use whole population testing, and when to stop testing&lt;/h2&gt;

&lt;p&gt;Despite the mathematical case for whole population testing, there are still valid reasons not to employ wide scale testing of asymptomatic people. There is still an acute shortage of test kits in many regions. Similarly, test processing capacity needs to be ramped up to support large-scale testing. Some institutions might not have sufficient funding for whole population testing in communities that feel the need to accept the risk of reopening without ideal precautions. Some communities may have so much contact with their ambient population that testing the entire community would be futile.&lt;/p&gt;

&lt;p&gt;For communities that are good candidates for whole population testing, the argument we are making may sound too aggressive, as if the argument does not allow for the end of testing. The purpose of testing the population is to reduce the prevalence of the disease to zero despite the nonzero prevalence of the disease in the ambient region. Testing can stop&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;when the prevalence of the disease in the region off-campus drops low enough to no longer be a threat to the health and lives of the campus community;&lt;/li&gt;
  &lt;li&gt;when a vaccine is widely available to the campus community;&lt;/li&gt;
  &lt;li&gt;when the region reaches herd immunity.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;What should Colleges and Communities do? There is no one-size-fits-all solution. What does seem clear is that unless campuses are willing to take dramatic measures that will be hard for colleges and universities to swallow, the outcome is likely to be grim. We have no choice but to pay a steep price while we wait for the endgame of this pandemic. We can choose to pay the financial costs of investing in the infrastructure and resources for wide-scale testing, or we can save our money and pay instead with the human lives of those that will succumb to the disease we choose not to test for.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&quot;footnotes&quot;&gt;Background image credit: &lt;a href=&quot;https://www.flickr.com/photos/governortomwolf/49628500797&quot;&gt;Governor Tom Wolf&lt;/a&gt;&lt;/div&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:ravens&quot;&gt;
      &lt;p&gt;This paradox is more popularly—and more boringly—called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Raven_paradox&quot;&gt;Raven Paradox&lt;/a&gt;. Unfortunately, we are no closer to understanding why a raven is like a writing desk.&amp;nbsp;&lt;a href=&quot;#fnref:ravens&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:turkeys&quot;&gt;
      &lt;p&gt;This does not constitute animal husbandry advice.&amp;nbsp;&lt;a href=&quot;#fnref:turkeys&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:wiggins&quot;&gt;
      &lt;p&gt;From Chris Wiggins, “What is Bayes’s theorem, and how can it be used to assign probabilities to questions such as the existence of God? What scientific value does it have?” Scientific American, Dec. 2005. Online: &lt;a href=&quot;https://www.scientificamerican.com/article/what-is-bayess-theorem-an/&quot;&gt;https://www.scientificamerican.com/article/what-is-bayess-theorem-an/&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;#fnref:wiggins&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:qpcr&quot;&gt;
      &lt;p&gt;The technique also detects an additional “control” gene inserted artificially as a baseline comparison for quantitative measurements. For the purposes of the present discussion, we care only about detecting the presence of the virus, not about quantifying viral load.&amp;nbsp;&lt;a href=&quot;#fnref:qpcr&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Robert Jacobson</name><email>rljacobson@gmail.com</email></author><category term="Mathematics" /><category term="Statistics" /><category term="COVID-19" /><category term="Healthcare" /><summary type="html">This article is an expanded version of the math part of an article I cowrote with marine biologist Dr. Andrew Rhyne about how many well-meaning public health professionals have misinterpreted the math behind test efficiency, Bayes’ Theorem. This misinterpretation has lead to dangerous public policy positions. Anyone with a math allergy is invited to read that article instead.</summary></entry><entry><title type="html">What is the IELR(1) Parsing Algorithm?</title><link href="/what-is-the-ielr1-parsing-algorithm" rel="alternate" type="text/html" title="What is the IELR(1) Parsing Algorithm?" /><published>2018-10-20T05:13:00-04:00</published><updated>2018-10-20T05:13:00-04:00</updated><id>/what-is-the-ielr1-parsing-algorithm</id><content type="html" xml:base="/what-is-the-ielr1-parsing-algorithm">&lt;p&gt;This short article is for those students, programmers, and computer scientists who already have a basic idea of what a parser is and does but who want to know what that mysterious reference to “IELR(1)” means in the &lt;a href=&quot;https://www.gnu.org/software/bison/&quot;&gt;Bison parser generator manual&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;the-ielr1-parsing-algorithm&quot;&gt;The IELR(1) Parsing Algorithm&lt;/h1&gt;
&lt;p&gt;The &lt;a href=&quot;https://doi.org/10.1016/j.scico.2009.08.001&quot;&gt;IELR(1) parsing algorithm was developed in 2008 by Joel E. Denny&lt;/a&gt; as part of his Ph.D. research under the supervision of Brian A. Malloy at Clemson University. The IELR(1) algorithm is a variation of the so-called &lt;a href=&quot;https://doi.org/10.1007/BF00290336&quot;&gt;“minimal” LR(1) algorithm developed by David Pager in 1977&lt;/a&gt;, which itself is a variation of the &lt;a href=&quot;https://doi.org/10.1007/BF00290336&quot;&gt;LR(k) parsing algorithm invented by Donald Knuth in 1965&lt;/a&gt;. The IE in IELR(1) stands for inadequacy elimination (see last section).&lt;/p&gt;

&lt;h2 id=&quot;lr1-algorithms&quot;&gt;LR(1) Algorithms&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Canonical_LR_parser&quot;&gt;LR(1)&lt;/a&gt; part of IELR(1) stands for &lt;strong&gt;L&lt;/strong&gt;eft to right, &lt;strong&gt;R&lt;/strong&gt;ightmost derivation with &lt;strong&gt;1&lt;/strong&gt; lookahead token. LR(1) parsers are also called canonical parsers. This class of parsing algorithms employs a bottom-up, shift-reduce parsing strategy with a stack and &lt;a href=&quot;https://en.wikipedia.org/wiki/State_transition_table&quot;&gt;state transition table&lt;/a&gt; determining the next action to take during parsing.&lt;/p&gt;

&lt;p&gt;Historically, LR(1) algorithms have been disadvantaged by large memory requirements for their transition tables. Pager’s improvement was to develop a method of combining the transition states when the transition table is generated, significantly reducing the size of the table. Thus Pager’s algorithm makes LR(1) parsers competitive with other parsing strategies with respect to space and time efficiency. The phrase “minimal LR(1) parser” refers to the minimal size of the transition table introduced by Pager’s algorithm.&lt;/p&gt;

&lt;h2 id=&quot;limitations-of-pagers-algorithm&quot;&gt;Limitations of Pager’s Algorithm&lt;/h2&gt;

&lt;p&gt;Minimal LR(1) algorithms produce the transition table based on a particular input grammar for the language to be parsed. Different grammars can produce the same language. Indeed, it is possible for a non-LR(1) grammar to produce an LR(1) parsable language. In practice, LR(1) parser generators accept non-LR(1) grammars with a specification for resolving conflicts between two possible state transitions (“shift-reduce conflicts”) to accommodate this fact. Denny and Malloy found that Pager’s algorithm fails to generate parsers powerful enough to parse LR(1) languages when provided certain non-LR(1) grammars even though the non-LR(1) grammar generates an LR(1) language.&lt;/p&gt;

&lt;p&gt;Denny and Malloy show that this limitation is not merely academic by demonstrating that Gawk and Gpic, both widely used, mature software, perform incorrect parser actions.&lt;/p&gt;

&lt;h2 id=&quot;ielr1s-improvements&quot;&gt;IELR(1)’s Improvements&lt;/h2&gt;

&lt;p&gt;Denny and Malloy studied the source of the deficiencies of Pager’s algorithm by comparing the transition table generated by Pager’s algorithm to the transition table of an equivalent LR(1) grammar and identified two sources of what they term &lt;em&gt;inadequacies&lt;/em&gt; that appear in the transition table from Pager’s algorithm but not in the LR(1) transition table. Denny and Malloy’s IELR(1) (&lt;em&gt;Inadequacy Elimination&lt;/em&gt; LR(1)) algorithm is an algorithm designed to &lt;em&gt;eliminate&lt;/em&gt; these &lt;em&gt;inadequacies&lt;/em&gt; when generating the transition table that is virtually identical in size to that of Pager’s algorithm.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;span style=&quot;font-size:x-small;&quot;&gt;This article is based on my &lt;a href=&quot;https://cs.stackexchange.com/questions/3461/what-is-an-ielr1-parser/99463#99463&quot;&gt;answer to a question on StackExchange&lt;/a&gt;.&lt;/span&gt;&lt;/p&gt;</content><author><name>Robert Jacobson</name><email>rljacobson@gmail.com</email></author><category term="Computer science" /><category term="compilers" /><summary type="html">This short article is for those students, programmers, and computer scientists who already have a basic idea of what a parser is and does but who want to know what that mysterious reference to “IELR(1)” means in the Bison parser generator manual.</summary></entry><entry><title type="html">Defining the Wolfram Language Part 2: Operator Properties</title><link href="/defining-the-wolfram-language-part-2-operator-properties" rel="alternate" type="text/html" title="Defining the Wolfram Language Part 2: Operator Properties" /><published>2018-09-04T20:26:00-04:00</published><updated>2018-09-04T20:26:00-04:00</updated><id>/defining-the-wolfram-language-part-2-operator-properties</id><content type="html" xml:base="/defining-the-wolfram-language-part-2-operator-properties">&lt;p&gt;In this third installment of our &lt;em&gt;n&lt;/em&gt; part series, “Defining the Wolfram Language,” we begin to study the properties, namely the arity, affix, associativity, and precedence, of the Mathematica operators we found in &lt;a href=&quot;defining-the-wolfram-language-part-1-finding-operators&quot;&gt;Part 1&lt;/a&gt;. If we ended Part 1 proud of our accomplishment—perhaps even a little smug—then we will get reacquainted with our humility in this article.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;For a refresher on what is meant by the words operator, arity, affix, associativity, and precedence, see &lt;a href=&quot;generalizing-pemdas-what-is-an-operator&quot;&gt;Generalizing PEMDAS: What is an operator?&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;programmatically-determining-properties-of-operators&quot;&gt;Programmatically determining properties of operators&lt;/h2&gt;

&lt;p&gt;We described several sources of data about Wolfram Language operators and their linguistic properties in &lt;a href=&quot;[Part 1](defining-the-wolfram-language-part-1-finding-operators)&quot;&gt;Part 1&lt;/a&gt;. Putting these different sources together gives you a database, but there are still some gaps in the dataset. As far as I know, though, these are the only operators anyone who isn’t an employee of Wolfram knows about.&lt;/p&gt;

&lt;p&gt;Is there a programmatic way to fill in the gaps in the resulting dataset once you know the operators, that is, what lexical tokens make up the operators? It’s easy to programmatically determine affix (prefix, infix, etc.) and arity (unary, binary, etc.) from the usage data that can be obtained from &lt;code class=&quot;highlighter-rouge&quot;&gt;WolframLanguageData&lt;/code&gt;, and we have everything we need for those operators listed in &lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Precedence is a lot harder. I have implemented a strategy that compares two operators by instantiating expressions involving the two operators and inspecting the result. The remainder of this section gives just a few examples to illustrate the fundamental reason why this strategy cannot work.&lt;/p&gt;

&lt;p&gt;Two synonyms of the same operator:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-wolfram&quot; data-lang=&quot;wolfram&quot;&gt;In[1]:= FullForm[Hold[a\[Conditioned]b&amp;lt;-&amp;gt;c]]
In[2]:= FullForm[Hold[a\[Conditioned]b\[TwoWayRule]c]]

Out[1]= Hold[Conditioned[a,TwoWayRule[b,c]]]
Out[2]= Hold[TwoWayRule[Conditioned[a,b],c]]&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The &lt;em&gt;only&lt;/em&gt; binary operator that cannot be parsed like this:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-wolfram&quot; data-lang=&quot;wolfram&quot;&gt;In[1]:= a \[DirectedEdge] b \[UndirectedEdge] c
    
Out[1]= Syntax::tsntxi: &quot;a\[DirectedEdge]b\[UndirectedEdge]c&quot; is incomplete; more input is needed.&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This next one is not uncommon:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-wolfram&quot; data-lang=&quot;wolfram&quot;&gt;In[1]:= FullForm[Hold[a \[LeftTee] b \[UpTee] c]]
In[2]:= FullForm[ToExpression[&quot;Hold[a \[LeftTee] b \[UpTee] c]&quot;]]
    
Out[1]= Hold[LeftTee[a,UpTee[b,c]]]
Out[2]= Hold[UpTee[LeftTee[a,b],c]]&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;There are several differences between the notebook and command line interfaces, and &lt;code class=&quot;highlighter-rouge&quot;&gt;ToExpression&lt;/code&gt; appears to precisely mirror those differences. Perhaps the command line and &lt;code class=&quot;highlighter-rouge&quot;&gt;ToExpression&lt;/code&gt; have the same parser. Whatever the case, we cannot assume that a piece of code will execute the same way on the command line as it will through the notebook interface.&lt;/p&gt;

&lt;p&gt;Many operators do not have a &lt;code class=&quot;highlighter-rouge&quot;&gt;FullForm&lt;/code&gt; (unevaluated interpretation) equal to the functions they represent. Consider &lt;code class=&quot;highlighter-rouge&quot;&gt;Divide&lt;/code&gt;:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-wolfram&quot; data-lang=&quot;wolfram&quot;&gt;In[1]:= (* Give the Head of the first element within Hold. *)
        Hold[a/b][[1, 0]]
    
Out[1]= Times&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Considering this one fact alone, whatever strategy one uses to inspect an instantiated expression to determine precedence will have to account for every special case of how the &lt;code class=&quot;highlighter-rouge&quot;&gt;FullForm&lt;/code&gt; of each operator might interact with that of another in a nongeneric way. The amount of manual labor one has to do to account for this is $Ω(n^2)$, where $n$ is the number operators.&lt;/p&gt;

&lt;p&gt;Then there is the case of &lt;code class=&quot;highlighter-rouge&quot;&gt;GreaterSlantEqual&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;LessSlantEqual&lt;/code&gt;, both the symbols and their corresponding functions. The short version is, these two symbols are now disassociated from their corresponding functions, which functions now have no operator notation despite the insistance of the documentation. To be clear, I think it’s the right move to remap the &lt;code class=&quot;highlighter-rouge&quot;&gt;*SlantEqual&lt;/code&gt; symbols to &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;gt;=&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;=&lt;/code&gt;, but…&lt;/p&gt;

&lt;h2 id=&quot;wolfram-language-as-language&quot;&gt;Wolfram Language as Language&lt;/h2&gt;

&lt;p&gt;We have seen that, even in a single version on a single platform, Mathematica itself does not always interpret Wolfram Language consistently in several dimensions:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The notebook interface versus &lt;code class=&quot;highlighter-rouge&quot;&gt;ToExpression&lt;/code&gt; and command line&lt;/li&gt;
  &lt;li&gt;Operator synonyms&lt;/li&gt;
  &lt;li&gt;With respect to the documentation&lt;/li&gt;
  &lt;li&gt;Associated (defining) functions of each operator versus how the input is immediately (re)interpreted; possibly equivalently, an expression’s &lt;code class=&quot;highlighter-rouge&quot;&gt;FullForm&lt;/code&gt; versus the literal interpretation of the expression as an application of its associated (defining) function&lt;/li&gt;
  &lt;li&gt;System-internal descriptions of operators like &lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;System`Convert`MLStringDataDump`$Operators&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To be clear, most inconsistencies in interpretation boil down to details of implementation choices that do not affect the output computed by a given expression. Whether &lt;code class=&quot;highlighter-rouge&quot;&gt;a-b&lt;/code&gt; is parsed as &lt;code class=&quot;highlighter-rouge&quot;&gt;Subtract[a, b]&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;Plus[a, Times[-1, b]]&lt;/code&gt; generally makes no difference in the final output. Other inconsistencies are a natural consequence of the fact that Mathematica is one of the most complex software systems ever created. The inconsistencies that are genuine bugs are almost all confined to recently introduced operators and outdated documentation. The differences in operator precedence between the notebook interface and &lt;code class=&quot;highlighter-rouge&quot;&gt;ToExpression&lt;/code&gt; and command line interface are more serious. However, consider:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;For the front end, however, a significant amount of specialized code is needed to support each different type of user interface environment. The front end contains about 700,000 lines of system‐independent C++ source code, of which roughly 200,000 lines are concerned with expression formatting. Then there are between 50,000 and 100,000 lines of specific code customized for each user interface environment.&lt;sup style=&quot;font-weight:bolder&quot; id=&quot;a1&quot; name=&quot;a1&quot;&gt;&lt;a href=&quot;#notes&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The language evolves just like any natural language evolves. There is no single Wolfram Language just as there is no single English language. We find ourselves with a curious postmodern synthesis of axiomatic mathematical systems and fluid human communication. Our hypothetical quest to lock down the syntax and semantics of Wolfram Language can only ever be Wolfram Language-&lt;em&gt;like&lt;/em&gt;, not only because of practical challenges of extracting accurate language information from Mathematica, or because a language spec will need to draw an arbitrary line between core language and auxiliary or incidental library content, or even because a bug-for-bug, quirk-for-quirk emulation of Mathematica’s behavior is impractical to achieve, but rather because the object of our study, Wolfram Langauge, is itself a thriving living organism changing and adapting to its environment, developing branches on which built-in symbolics like &lt;a href=&quot;https://reference.wolfram.com/language/ref/Black.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Black&lt;/code&gt;&lt;/a&gt; are eschewed in favor of strings like &lt;a href=&quot;https://reference.wolfram.com/language/ref/EntityValue.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;EntityCount&quot;&lt;/code&gt;&lt;/a&gt;, tendrils where option patterns are replaced with optional arguments or even Free-form Input, appendages where textual expression representations are replaced with opaque graphical object representations like the instantiation of &lt;a href=&quot;https://reference.wolfram.com/language/ref/LinearLayer.html#352245294&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;LinearLayer[5]&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Stephen Wolfram has written about how decisions are made for the design of Wolfram Language:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I’ve worked very hard over the past 30 plus years to maintain the unity and coherence of the Wolfram Language. But every day I’m doing meetings where we decide about new things to be added to the language—and it’s always a big challenge and a big responsibility to maintain the standards we’ve set, and to make sure that the decisions we make today will serve us well in the years to come.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;It could be about our symbolic framework for neural nets. Or about integrating with databases. Or how to represent complex engineering systems. Or new primitives for functional programming. Or new forms of geo visualization. Or quantum computing. Or programmatic interactions with mail servers. Or the symbolic representation of molecules. Or a zillion other topics that the Wolfram Language covers now, or will cover in the future.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;What are the important functions in a particular area? How do they relate to other functions? Do they have the correct names? How can we deal with seemingly incompatible design constraints? Are people going to understand these functions? Oh, and are related graphics or icons as good and clear and elegant as they can be?&lt;sup style=&quot;font-weight:bolder&quot; id=&quot;a2&quot; name=&quot;a2&quot;&gt;&lt;a href=&quot;#design&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://www.stephenwolfram.com/livestreams/&quot;&gt;Stephen livestreams many of his language design meetings&lt;/a&gt;. It is fascinating to watch the language evolve in realtime and the designers identify and wrestle with often very subtle but important design challenges. What is clear is that Wolfram Language is designed very differently from other programming languages, and I think this difference is precisely because other langauges, generally speaking, are intentionally designed with limitations of expressibility. As a corollary, most successful programming languages change only very slowly or else stand completely still.&lt;/p&gt;

&lt;p&gt;Or, from another point of view, Wolfram Langauge embraces the principle of &lt;em&gt;orthogonality&lt;/em&gt;, that there should only be a small number of independent fundamental langauge features that are sufficient to express all other aspects of the language, illustrated by the differences between Lisp-like langauges and, say, C++.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This is
one great advantage of Lisp-like languages: They have very few ways of forming compound
expressions, and almost no syntactic structure. All of the formal properties can be covered in an hour,
like the rules of chess. After a short time we forget about syntactic details of the language (because
there are none) and get on with the real issues – figuring out what we want to compute, how we will
decompose problems into manageable parts, and how we will work on the parts. &lt;sup style=&quot;font-weight:bolder&quot; id=&quot;a2&quot; name=&quot;a2&quot;&gt;&lt;a href=&quot;#scip&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Computer scientist Alan J. Perlis writes in the forward to &lt;a href=&quot;#scip&quot;&gt;[3]&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;It would be difficult to find two languages that are the communicating coin of two more
different cultures than those gathered around these two languages [Lisp and Pascal]. Pascal is for building pyramids — imposing, breathtaking, static structures built by armies pushing heavy blocks into place. Lisp is for
building organisms — imposing, breathtaking, dynamic structures built by squads fitting fluctuating
myriads of simpler organisms into place. The organizing principles used are the same in both cases,
except for one extraordinarily important difference: The discretionary exportable functionality
entrusted to the individual Lisp programmer is more than an order of magnitude greater than that to be
found within Pascal enterprises. Lisp programs inflate libraries with functions whose utility transcends
the application that produced them. The list, Lisp’s native data structure, is largely responsible for such
growth of utility. The simple structure and natural applicability of lists are reflected in functions that
are amazingly nonidiosyncratic. In Pascal the plethora of declarable data structures induces a
specialization within functions that inhibits and penalizes casual cooperation. It is better to have 100
functions operate on one data structure than to have 10 functions operate on 10 data structures. As a
result the pyramid must stand unchanged for a millennium; the organism must evolve or perish.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For languages designed in the spirit of Lisp, operator syntax is only window dressing. In fact, in many such languages, the syntax and semantics of operators—or even numeric literals!—can even be redefined by the programmer. This is possible to a limited extent in Wolfram Language, but more importantly, all operators in Wolfram Language are merely syntactic sugar for their &lt;code class=&quot;highlighter-rouge&quot;&gt;FullForm&lt;/code&gt; counterparts.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Our journey through the landscape of Wolfram Language operator syntax has been a necessary and instructive part of our hypothetical project of rigorously describing the Wolfram Language. The previous section suggests, however, that operator syntax is primarily an ergonomic layer between the human programmer and the underlying language semantics and behavior. The most important language features are those which transcend a particular operator syntax. If all there were in Wolfram Language were &lt;code class=&quot;highlighter-rouge&quot;&gt;FullForm&lt;/code&gt; expressions, very little of the language would be lost.&lt;/p&gt;

&lt;p&gt;What would remain? We have so far only concerned ourselves with the surface details of Wolfram Language. We will now turn from the question, “What does it look like?,” to the question, “How does it work?” Every programming language requires some notion of data, types, operations, and runtime environment, even if one or more of these catagories is combined with another, as when functions can be treated as data, or concealed from the programmer, as in so-called “untyped” languages. Some language characteristics, such as how names are ascribed and resolved, may involve all four of these notions at once. A useful langauge spec will lay out these language subsystems and describe how they interact.&lt;/p&gt;

&lt;p&gt;The boundary between that which is language definition and that which is “implementation defined,” that is, a choice left to the language implementor, will continue to be blurry. Ambiguity and undefined behavior is unavoidable despite its offence to our inner mathematician. But it also gives us freedom to make our own choices about what is correct—or even correct the mistakes of the original language designers.&lt;/p&gt;

&lt;p&gt;As I consider the rigorous intellectual work required to map out a mature, serious language like Wolfram Language—there are mathematical and engineering mountains to climb—I am reminded again of the words of Alan Perlis who imagined the perpetual compounding complexity of computer systems and the mathematical and software engineering technologies required to tame them:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Each breakthrough in hardware technology leads to more massive programming enterprises, new organizational principles, and an enrichment of abstract models. Every
reader should ask himself periodically ‘‘Toward what end, toward what end?’’ — but do not ask it too
often lest you pass up the fun of programming for the constipation of bittersweet philosophy.&lt;sup style=&quot;font-weight:bolder&quot;&gt;&lt;a href=&quot;#scip&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I now adapt Perlis’ poetic words as we end: &lt;em&gt;Invent and fit; have fits and reinvent! We toast the Wolfram Language programmer who pens their thoughts within nests of brackets.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a name=&quot;notes&quot;&gt;[1]&lt;/a&gt;: &lt;span style=&quot;font-size:85%&quot;&gt; “&lt;a href=&quot;https://reference.wolfram.com/language/tutorial/TheSoftwareEngineeringOfTheWolframSystem.html&quot;&gt;The Software Engineering of the Wolfram System&lt;/a&gt;,” from the &lt;em&gt;Wolfram Language &amp;amp; System Documentation Center&lt;/em&gt;. Retrieved September 4, 2018. This article appears to have been written when Mathematica was on Version 6. It is reasonable to assume the code statistics are more dramatic for Mathematica versions ≥ 11.3. &lt;/span&gt; &lt;a href=&quot;#a1&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;design&quot;&gt;[2]&lt;/a&gt;: &lt;span style=&quot;font-size:85%&quot;&gt; Stephen Wolfram, “&lt;a href=&quot;https://www.wired.com/story/what-do-i-do-all-day-livestreamed-technology-ceoing/&quot;&gt;What Do I Do All Day? Livestreamed Technology CEOing&lt;/a&gt;,” &lt;em&gt;Wired&lt;/em&gt;, November 11, 2017. Retrieved September 4, 2018. &lt;/span&gt; &lt;a href=&quot;#a2&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;sicp&quot;&gt;[3]&lt;/a&gt;: &lt;span style=&quot;font-size:85%&quot;&gt; Harold Abelson, Gerald Jay Sussman, and Julie Sussman, &lt;em&gt;The Structure and Interpretation of Computer Programs&lt;/em&gt;, Second Edition (1996), MIT Press. &lt;br /&gt;This classic programming text has introduced generations of programmers and computer scientists to the “different cultures” surrounding Lisp-like languages and Pascal-like languages—and to the computer science common to both. &lt;/span&gt; &lt;a href=&quot;#a3&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;</content><author><name>Robert Jacobson</name><email>rljacobson@gmail.com</email></author><category term="Computer science" /><category term="compilers" /><category term="Mathematica" /><summary type="html">In this third installment of our n part series, “Defining the Wolfram Language,” we begin to study the properties, namely the arity, affix, associativity, and precedence, of the Mathematica operators we found in Part 1. If we ended Part 1 proud of our accomplishment—perhaps even a little smug—then we will get reacquainted with our humility in this article.</summary></entry><entry><title type="html">Generalizing PEMDAS: What is an operator?</title><link href="/generalizing-pemdas-what-is-an-operator" rel="alternate" type="text/html" title="Generalizing PEMDAS: What is an operator?" /><published>2018-09-03T11:30:00-04:00</published><updated>2018-09-03T11:30:00-04:00</updated><id>/generalizing-pemdas-what-is-an-operator</id><content type="html" xml:base="/generalizing-pemdas-what-is-an-operator">&lt;p&gt;In programming languages, an &lt;em&gt;operator&lt;/em&gt; is a symbol used to represent a specific operation such as subtraction of integers or dereferencing a pointer. The symbols &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;!&lt;/code&gt; are commonly used as operators in many programming languages, for example. In this article we define some basic programming language terminology that allows us to categorize operators according to their different properties.&lt;/p&gt;

&lt;h2 id=&quot;computation-with-expressions&quot;&gt;Computation with Expressions&lt;/h2&gt;

&lt;p&gt;Virtually all programming languages have &lt;em&gt;expressions&lt;/em&gt;, like &lt;code class=&quot;highlighter-rouge&quot;&gt;2 + 4&lt;/code&gt;, which consist of &lt;em&gt;operators&lt;/em&gt; (the &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt; operator in &lt;code class=&quot;highlighter-rouge&quot;&gt;2 + 4&lt;/code&gt;) and their &lt;em&gt;operands&lt;/em&gt; (or &lt;em&gt;arguments&lt;/em&gt;; the &lt;code class=&quot;highlighter-rouge&quot;&gt;2&lt;/code&gt; and the &lt;code class=&quot;highlighter-rouge&quot;&gt;4&lt;/code&gt;), that is, the things operators operate on.  This language is barrowed from mathematics where, for example, $17/2 + \sin(\pi/2)$ is an expression that &lt;em&gt;evaluates&lt;/em&gt; to the &lt;em&gt;value&lt;/em&gt; $19/2$. Most programming languages also have other language constructs like statements and declarations that are not expressions. In some languages, like Wolfram Language, &lt;a href=&quot;https://reference.wolfram.com/language/tutorial/EverythingIsAnExpression.html&quot;&gt;&lt;em&gt;everything is an expression&lt;/em&gt;&lt;/a&gt;. In these languages, an entire program itself is an expression, albeit possibly a very complex one, and executing a program is called &lt;em&gt;evaluation&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;properties-of-operators&quot;&gt;Properties of Operators&lt;/h2&gt;

&lt;h3 id=&quot;arity&quot;&gt;Arity&lt;/h3&gt;

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Arity&quot;&gt;arity&lt;/a&gt; of an operator is just a fancy word for how many operands (arguments) the operator takes. Here are some common examples:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Arity&lt;/th&gt;
      &lt;th&gt;Operator&lt;/th&gt;
      &lt;th&gt;Example Expression&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;“Nullary”&lt;br /&gt; (takes no arguments)&lt;/td&gt;
      &lt;td&gt;Constants&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Unary&lt;/td&gt;
      &lt;td&gt;Factorial: &lt;code class=&quot;highlighter-rouge&quot;&gt;!&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;$3! = 3 \cdot 2 \cdot 1 = 6$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Binary&lt;/td&gt;
      &lt;td&gt;Addition: &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;$2 + 4 = 6$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ternary&lt;/td&gt;
      &lt;td&gt;The conditional operator &lt;br /&gt;found in many languages: &lt;br /&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;a ? b : c&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;// if a&amp;gt;b then x else y&lt;/code&gt; &lt;br /&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;result = a &amp;gt; b ? x : y; &lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Variadic &lt;br /&gt;(takes a variable number &lt;br /&gt;of arguments)&lt;/td&gt;
      &lt;td&gt;Lists: &lt;code class=&quot;highlighter-rouge&quot;&gt;{x, y, ...}&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;{ }&lt;/code&gt; (empty list); &lt;br /&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;{2, 3, 5, 7, 11}&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$n$-ary &lt;br /&gt;(takes $n$ arguments)&lt;/td&gt;
      &lt;td&gt;A function of $n$ arguments:&lt;br /&gt; $f(a_1, a_2, \ldots, a_n)$&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;DeleteCases[expr, pattern,&lt;/code&gt;&lt;br /&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt; levelspec, n]&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;You will occassionally see authors abuse the language above by using &lt;em&gt;n-ary&lt;/em&gt; to mean &lt;em&gt;variadic&lt;/em&gt;. The Wikipedia article on &lt;a href=&quot;https://en.wikipedia.org/wiki/Arity&quot;&gt;arity&lt;/a&gt; has a long list of obscure names for different arities.&lt;/p&gt;

&lt;h3 id=&quot;affix&quot;&gt;Affix&lt;/h3&gt;

&lt;p&gt;The &lt;em&gt;affix&lt;/em&gt; of an operator refers to the operator’s position within an expression with respect to its operands. Again, some common examples:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Affix&lt;/th&gt;
      &lt;th&gt;Operator&lt;/th&gt;
      &lt;th&gt;Example Expression&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Prefix: precedes its operand(s)&lt;/td&gt;
      &lt;td&gt;Unary minus: &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;$-7$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Postfix: follows its operand(s)&lt;/td&gt;
      &lt;td&gt;Factorial: &lt;code class=&quot;highlighter-rouge&quot;&gt;!&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;$3!$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Infix: between its operands&lt;/td&gt;
      &lt;td&gt;Addition: &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;$2 + 4$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Matchfix (Circumfix): surrounds its operand(s)&lt;/td&gt;
      &lt;td&gt;Floor function: &lt;code class=&quot;highlighter-rouge&quot;&gt;⌊ ⌋&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;$\lfloor{2.78}\rfloor = 2$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The affix of operators with more than two operands defy easy categorization. To illustrate, suppose we wish to invent our own ternary operator, and we have the symbols &lt;code class=&quot;highlighter-rouge&quot;&gt;@&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;#&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;$&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;amp;&lt;/code&gt; available to use to represent our operator if we need them. If &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt; are operands, then we could define the operator as &lt;code class=&quot;highlighter-rouge&quot;&gt;@ a # b $ c &amp;amp;&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;a # b $ c &amp;amp;&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;@ a # b $ c&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;a # b $ c&lt;/code&gt;. Or instead of using different symbols to separate the operands, we could use just one symbol, as Wolfram Language does with the &lt;code class=&quot;highlighter-rouge&quot;&gt;Span&lt;/code&gt; operator: &lt;code class=&quot;highlighter-rouge&quot;&gt;start ;; stop ;; step&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;associativity&quot;&gt;Associativity&lt;/h3&gt;

&lt;p&gt;The &lt;em&gt;associativity&lt;/em&gt; of an operator determines how an operator &lt;em&gt;groups&lt;/em&gt; with expressions around it. Consider the exponentiation (power) operator &lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt; in the expression &lt;code class=&quot;highlighter-rouge&quot;&gt;2^3^2&lt;/code&gt;$=2^{3^2}$, which is a perfectly valid expression in many programming languages and in mathematics. Setting aside mathematical tradition, this expression &lt;em&gt;could&lt;/em&gt; mean either &lt;code class=&quot;highlighter-rouge&quot;&gt;(2^3)^2&lt;/code&gt; $= (2^3)^2 = $ &lt;code class=&quot;highlighter-rouge&quot;&gt;8^2 = 64&lt;/code&gt;, but it could also mean &lt;code class=&quot;highlighter-rouge&quot;&gt;2^(3^2)&lt;/code&gt; $= 2^{(3^2)} = $ &lt;code class=&quot;highlighter-rouge&quot;&gt;2^9 = 512&lt;/code&gt;. These are clearly very different meanings! In the first interpretation, we say the &lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt; operator &lt;em&gt;associates to the left&lt;/em&gt;, because the left-most operation is done first. In the second interpretation, we say the &lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt; operator &lt;em&gt;associates to the right&lt;/em&gt;. Mathematical tradition and most programming languages define &lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt; as right associative.&lt;/p&gt;

&lt;h3 id=&quot;precedence&quot;&gt;Precedence&lt;/h3&gt;

&lt;p&gt;You may recall from elementary school that some mathematical operators must be done before others. In the expression  $2+3\times 5$, for example, we need to multiply the 3 by 5 before we do the addition: $2+3\times 5 = 2+(3\times 5) = 2+15 = 17$. If we fail to follow the correct order of operations, we are likely to get the wrong answer: $2+3\times 5 \neq (2 + 3) \times 5 = 5 \times 5 = 25 \neq 17$. School children learn the correct order of operations by remembering the initialism “PEMDAS” or, “&lt;u&gt;P&lt;/u&gt;lease &lt;u&gt;E&lt;/u&gt;xcuse &lt;u&gt;M&lt;/u&gt;y &lt;u&gt;D&lt;/u&gt;ear &lt;u&gt;A&lt;/u&gt;unt &lt;u&gt;S&lt;/u&gt;ally,” which assigns the arithmetic operators the precedence:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Parentheses&lt;/li&gt;
  &lt;li&gt;Exponents&lt;/li&gt;
  &lt;li&gt;Multiplication&lt;/li&gt;
  &lt;li&gt;Division&lt;/li&gt;
  &lt;li&gt;Addition&lt;/li&gt;
  &lt;li&gt;Subtraction&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;(In fact, we usually give multiplication the same precedence as division, and addition the same precedence as subtraction.)  The numbers in the list above are called precedence levels and tell us the order each operation is performed when an expression is evaluated. If we expand our list of operators, we must decide which operations should precede which other operations during evaluation of the expression, that is, what precedence each operator should have.&lt;/p&gt;

&lt;p&gt;An equivalent way of thinking of the precedence of an operator is as the “binding power” of the operator. In the expression $2+3\times 5$, we say that the $\times$ operator binds more tightly to nearby expressions (numbers, in this case) than does the $+$ operator, and consequently $2+3\times 5 = 2+(3\times 5)$&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The arity, affix, associativity, and precedence of an operator are essential to know in order to determine which parts of an expression a given operator is acting on and therefore how the expression should be evaluated. A parser for a programming language is responsible for correctly interpreting its input according to these operator properties. In fact, some parsing strategies rely entirely on operator properties to interpret the meaning of expressions in programs.&lt;/p&gt;</content><author><name>Robert Jacobson</name><email>rljacobson@gmail.com</email></author><category term="Computer science" /><category term="compilers" /><summary type="html">In programming languages, an operator is a symbol used to represent a specific operation such as subtraction of integers or dereferencing a pointer. The symbols +, *, and ! are commonly used as operators in many programming languages, for example. In this article we define some basic programming language terminology that allows us to categorize operators according to their different properties.</summary></entry><entry><title type="html">Defining the Wolfram Language Part 1: Finding Operators</title><link href="/defining-the-wolfram-language-part-1-finding-operators" rel="alternate" type="text/html" title="Defining the Wolfram Language Part 1: Finding Operators" /><published>2018-08-16T15:26:00-04:00</published><updated>2018-08-16T15:26:00-04:00</updated><id>/defining-the-wolfram-language-part-1-finding-operators</id><content type="html" xml:base="/defining-the-wolfram-language-part-1-finding-operators">&lt;h1 id=&quot;finding-all-wolfram-language-operators&quot;&gt;Finding All Wolfram Language Operators&lt;/h1&gt;

&lt;p&gt;In this second article, Part 1 of an &lt;em&gt;n&lt;/em&gt; part series on &lt;em&gt;Defining the Wolfram Language&lt;/em&gt;, we start getting our hands dirty hunting down every single operator in Mathematica and each operator’s linguistic properties. To my knowledge, nobody outside of Wolfram has created such an exhaustive list before.&lt;!--more--&gt; The operator properties we hope to document are arity, affix, associativity, and precedence. In the next article, “&lt;a href=&quot;generalizing-pemdas-what-is-an-operator&quot;&gt;Generalizing PEMDAS: What is an operator?&lt;/a&gt;,” we will define and discuss the signficance of these linguistic properties of operators for programming languages generally. If these terms are foreign to you, do not worry, you will not need to know what these terms mean for this article, but you can read the next article before reading Part 1 without any confusion.&lt;/p&gt;

&lt;h2 id=&quot;data-sources&quot;&gt;Data Sources&lt;/h2&gt;

&lt;p&gt;It is surprisingly difficult to get accurate information about all Wolfram Language operators implemented in Mathematica. There are a few different sources of information about operators and their properties. I list all publicly known sources (as of August 2018) in the table below, the last two of which appear to be described nowhere else on the public internet. We will explore these sources in more detail in the remainder of this section.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Source&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://reference.wolfram.com/language/&quot;&gt;Official Documentation&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;The most common operators only. Usually no precedence or associativity.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://reference.wolfram.com/language/ref/WolframLanguageData.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;WolframLanguageData[]&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;Only has info for most common operators. For most operators, gives precedence rank, arity, affix. Less often associativity info is apparent.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence[]&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Undocumented built-in function. When provided the long name of an operator, gives precedence. Only works with some operators and is often incorrect.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Gives explicit precedence, affix, and associativity for 338 operators that are a single Unicode character outside of ASCII character set. Note that this system file uses a different precedence numbering scheme than other sources and which applies only to the notebook interface.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;`System`Convert`&lt;/code&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;MLStringDataDump`&lt;/code&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;$ExtractedOperators&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Undocumented list of 272 single character unicode operators all but one of which is in &lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt;. A proper subset of the next source, but I include it for completeness.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;System`Convert`&lt;/code&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;MLStringDataDump`&lt;/code&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;$Operators&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Undocumented list of 340 operators—characters only. Includes most operators, even single and multi-character ASCII operators. Excludes Association brackets, box operators, and obscure bracketing operators.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Internal`SymbolNameQ[]&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Undocumented function that apparently identifies a string as a “symbol name.” Computing the complement of the set of Unicode characters for which &lt;code class=&quot;highlighter-rouge&quot;&gt;SymbolNameQ&lt;/code&gt; evaluates to True gives a list of operators, including some single-character box operators found in no other list.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Of the sources in this table, the only ones that are &lt;em&gt;documented&lt;/em&gt; are &lt;code class=&quot;highlighter-rouge&quot;&gt;WolframLanguageData&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt;, and (by definition) the official documentation, and &lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt; is only documented in the sense that &lt;a href=&quot;https://reference.wolfram.com/language/Notation/tutorial/ComplexPatternsAndAdvancedFeatures.html&quot;&gt;it is mentioned exactly once seemingly in passing in the official documentation&lt;/a&gt; (although see below). It is important to understand that no single source contains all operators, and all but &lt;code class=&quot;highlighter-rouge&quot;&gt;$ExtractedOperators&lt;/code&gt; and (ironically) the official documentation are necessary to obtain all available information about all operators.&lt;/p&gt;

&lt;h3 id=&quot;the-official-documentation&quot;&gt;The Official Documentation&lt;/h3&gt;

&lt;p&gt;The first place to look for anyone interested in learning about Mathematica’s operators is the operator table given in the &lt;a href=&quot;https://wolfr.am/wS1xS8bZ&quot;&gt;Operator Input Forms&lt;/a&gt; documentation. This table claims to give operator precedence (in the form of “precedence rank”), associativity, and usage information from which arity and affix are apparent. Unfortunately, you will find that this table is sometimes incorrect, woefully incomplete, and certainly outdated. There are several cases of multiple precedence levels being incorrectly represented in the table as a single precedence level. Associativity information for many listed operators is missing. (&lt;code class=&quot;highlighter-rouge&quot;&gt;TagSet&lt;/code&gt; is right associative, for example.) Finally, nearly 200 operators are either missing or are listed en mass under labels like, “other ordering operators.”&lt;/p&gt;

&lt;p&gt;Other pages of the official documentation, while often very helpful for learning Mathematica, usually do not give information about associativity and precedence. Mathematica’s documentation, in my opinion, is generally superlative and sets the standard by which all other documentation should be measured. Even so, it contains a great number of errors and is simply not intended to stand in for the kind of language spec needed by, e.g., compiler tool authors that is motivating our study.&lt;/p&gt;

&lt;h3 id=&quot;the-undocumented-precedence-function&quot;&gt;The Undocumented &lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence[]&lt;/code&gt; Function&lt;/h3&gt;

&lt;p&gt;Advanced Mathematica programmers frequently pop up on &lt;a href=&quot;https://mathematica.stackexchange.com/&quot;&gt;mathematica.stackexchange.com&lt;/a&gt; asking about how to choose a Mathematica operator without a built-in meaning (of which there are many) that has just the right operator precedence they need for their use case. The answer given by the Mathematica gurus is almost invariably to use the undocumented &lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence[]&lt;/code&gt; function. I am sorry to report that on this point the Mathematica gurus are giving bad advice. Here are a few problems with the &lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence[]&lt;/code&gt; function:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;It takes the (symbolic) names of operators, not symbols. For example, &lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence[Element]&lt;/code&gt; evaluates to &lt;code class=&quot;highlighter-rouge&quot;&gt;250.&lt;/code&gt;, but &lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence[∈]&lt;/code&gt; predictably fails with a syntax error. Consequently, you need to know the symbolic name of the operator you are interested in.&lt;sup style=&quot;font-weight:bolder&quot; id=&quot;a1&quot; name=&quot;a1&quot;&gt;&lt;a href=&quot;#opnames&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
  &lt;li&gt;As a corollary to (1), if an operator &lt;em&gt;has no name&lt;/em&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence&lt;/code&gt; is useless. This is not an obscure problem, as there are several important operators with no apparent name, such as the square brackets operator for function application &lt;code class=&quot;highlighter-rouge&quot;&gt;f[e]&lt;/code&gt;.&lt;sup style=&quot;font-weight:bolder&quot; id=&quot;a1&quot; name=&quot;a1&quot;&gt;&lt;a href=&quot;#opnames&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence&lt;/code&gt; fails to return a true precedence level for roughly 10% of the operators that do have names. &lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence&lt;/code&gt; indicates failure by returning &lt;code class=&quot;highlighter-rouge&quot;&gt;670.&lt;/code&gt;, which is inconvenient since &lt;code class=&quot;highlighter-rouge&quot;&gt;670.&lt;/code&gt; is a valid precedence level.&lt;/li&gt;
  &lt;li&gt;The same symbolic name can be associated to both the unary and binary operators associated to the function. For example, &lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence[PlusMinus]&lt;/code&gt; gives the precedence of the unary operator &lt;code class=&quot;highlighter-rouge&quot;&gt;±x&lt;/code&gt; (&lt;code class=&quot;highlighter-rouge&quot;&gt;310.&lt;/code&gt;) rather than the precedence of the binary operator &lt;code class=&quot;highlighter-rouge&quot;&gt;x ± y&lt;/code&gt; (&lt;code class=&quot;highlighter-rouge&quot;&gt;480.&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence&lt;/code&gt; combines precedence levels that should be split—but not as much as the &lt;a href=&quot;https://wolfr.am/wS1xS8bZ&quot;&gt;Operator Input Forms&lt;/a&gt; documentation.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence&lt;/code&gt; is sometimes just plain wrong. For example, contrary to &lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Union&lt;/code&gt; has a higher precedence than &lt;code class=&quot;highlighter-rouge&quot;&gt;Span&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We have spent a lot of ink explaining why the official documentation, the &lt;a href=&quot;https://wolfr.am/wS1xS8bZ&quot;&gt;Operator Input Forms&lt;/a&gt; table in particular, and the &lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence[]&lt;/code&gt; function are not the best sources of information about Mathematica operators in part to correct the record on the subject, as these two sources are what come up the most often in technical discussions, even among experts. But we have made only meager progress toward our goal of accurately documenting every Mathematica operator. Where &lt;em&gt;should&lt;/em&gt; we—and the gurus on &lt;a href=&quot;https://mathematica.stackexchange.com/&quot;&gt;mathematica.stackexchange.com&lt;/a&gt;—be looking if not to these sources?&lt;/p&gt;

&lt;p&gt;For most purposes, we should look to &lt;a href=&quot;https://reference.wolfram.com/language/ref/WolframLanguageData.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;WolframLanguageData[]&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;wolframlanguagedata&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;WolframLanguageData[]&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;I have found that the precedence rank returned by &lt;a href=&quot;https://reference.wolfram.com/language/ref/WolframLanguageData.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;WolframLanguageData[]&lt;/code&gt;&lt;/a&gt; is more accurate than the &lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence&lt;/code&gt; function. As a bonus, &lt;code class=&quot;highlighter-rouge&quot;&gt;WolframLanguageData&lt;/code&gt; gives you really nice operator synonym, usage, and FullForm data, and programmatic access to all kinds of information related to Mathematica functions and their documentation.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-wolfram&quot; data-lang=&quot;wolfram&quot;&gt;In[1]:= WolframLanguageData[&quot;Power&quot;, &quot;PrecedenceRanks&quot;]

Out[1]= {{expr1\_expr2\%expr3, Power[Subscript[expr1,expr2],expr3]}-&amp;gt;8,
        {expr1^expr2, Power[expr1,expr2]}-&amp;gt;21,
        {expr1^expr2, Power[expr1,expr2]}-&amp;gt;21,
        {expr1^expr2, Power[expr1,expr2]}-&amp;gt;21,
        {Subsuperscript[expr1, expr2, expr3],
            Power[Subscript[expr1,expr2],expr3]}-&amp;gt;21,
        {expr1\^expr2\%expr3, Power[Subscript[expr1,expr3],expr2]}-&amp;gt;21,
        {\@expr\%n,Power[expr,Power[n,-1]]}-&amp;gt;22}&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Another bonus of &lt;code class=&quot;highlighter-rouge&quot;&gt;WolframLanguageData&lt;/code&gt; is that you do not already have to know the name of every function with an operator. You can ask &lt;code class=&quot;highlighter-rouge&quot;&gt;WolframLanguageData&lt;/code&gt; to just give you everything in its database, which includes the box sublanguage. The following will generate a list for you. Be warned that it will download data for all 5,000+ functions and ultimately give you a list of 135 (as of August 2018) &lt;code class=&quot;highlighter-rouge&quot;&gt;{name, rankdata, shortnotation}&lt;/code&gt; triples:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-wolfram&quot; data-lang=&quot;wolfram&quot;&gt;In[1]:= Select[
            WolframLanguageData[
                WolframLanguageData[&quot;Entities&quot;], 
                {&quot;Name&quot;, &quot;PrecedenceRanks&quot;, &quot;ShortNotations&quot;}
            ], 
            #[[2]] =!= Missing[&quot;NotApplicable&quot;] &amp;amp;
        ]&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;ShortNotations&quot;&lt;/code&gt; data provided by &lt;code class=&quot;highlighter-rouge&quot;&gt;WolframLanguageData&lt;/code&gt; leaves a lot to be desired, and while arity and affix are usually apparent from the usage data, &lt;code class=&quot;highlighter-rouge&quot;&gt;WolframLanguageData&lt;/code&gt; usually does not provide enough information to deduce operator associativity. Unfortunately, &lt;code class=&quot;highlighter-rouge&quot;&gt;WolframLanguageData&lt;/code&gt; will not give you every operator, either. However, this is the &lt;em&gt;only&lt;/em&gt; source outside of the documentation itself that gives all multicharacter box operators. With some effort, it is possible to use &lt;code class=&quot;highlighter-rouge&quot;&gt;WolframLanguageData&lt;/code&gt; to programmatically extract even more information about operators from the documentation, but the information earned by this effort is much easier to obtain elsewhere.&lt;/p&gt;

&lt;p&gt;Let’s dive deeper.&lt;/p&gt;

&lt;h3 id=&quot;unicodecharacterstr&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;The Mathematica system files include a file named &lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt; that appears to contain information about how the Mathematica frontend interprets ~1100 Unicode characters. As its name implies, the &lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt; file appears to only include characters that are &lt;em&gt;single&lt;/em&gt; Unicode characters &lt;em&gt;outside&lt;/em&gt; of the ASCII character set. It does not include &lt;code class=&quot;highlighter-rouge&quot;&gt;!&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;/@&lt;/code&gt;, for example. Most people describe the file as “undocumented,” but in fact &lt;a href=&quot;https://reference.wolfram.com/language/Notation/tutorial/ComplexPatternsAndAdvancedFeatures.html&quot;&gt;it is mentioned exactly once in the official documentation&lt;/a&gt; for the Notation Package:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“The &lt;code class=&quot;highlighter-rouge&quot;&gt;SyntaxForm&lt;/code&gt; option value can be any operator string valid in the Wolfram Language, that is, any operator contained in the UnicodeCharacters.tr file.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(As an aside, this line in the documentation is incorrect in the sense that &lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt; does not include every operator string valid in the Wolfram Language, ASCII operator strings in particular, while these missing operator strings are still valid values for the &lt;code class=&quot;highlighter-rouge&quot;&gt;SyntaxForm&lt;/code&gt; option.)&lt;/p&gt;

&lt;p&gt;Most of the records in the file are &lt;em&gt;not&lt;/em&gt; operators, but for the operators that are included, it gives us the most detailed syntactic information of any source. Each record has up to 9 columns (fields) that we might label as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Hex Code&lt;/li&gt;
  &lt;li&gt;Long Name&lt;/li&gt;
  &lt;li&gt;Alternative Input Methods&lt;/li&gt;
  &lt;li&gt;Class/Affix&lt;/li&gt;
  &lt;li&gt;Precedence&lt;/li&gt;
  &lt;li&gt;Associativity&lt;/li&gt;
  &lt;li&gt;Left Spacing&lt;/li&gt;
  &lt;li&gt;Right Spacing&lt;/li&gt;
  &lt;li&gt;Rendered As&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This is everything we could hope to know about the linguistics of an operator—the proverbial holy grail of operator syntax. Be aware that it uses a &lt;em&gt;different&lt;/em&gt; precedence numbering scheme from &lt;code class=&quot;highlighter-rouge&quot;&gt;Precedence[]&lt;/code&gt;, so be sure not to mix up the two. Note also that the precedence in the &lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt; refers to precedence within the frontend only. (The meaning of this last sentence will become clear in the section, “Programmatically determining properties of operators.”)&lt;/p&gt;

&lt;p&gt;This code snippet reads the data from &lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt; into the variable &lt;code class=&quot;highlighter-rouge&quot;&gt;chars&lt;/code&gt;:&lt;sup style=&quot;font-weight:bolder&quot; id=&quot;a2&quot; name=&quot;a2&quot;&gt;&lt;a href=&quot;#mrwizard&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-wolfram&quot; data-lang=&quot;wolfram&quot;&gt;In[1]:= chars = ReadList[
            System`Dump`unicodeCharactersTR, 
            Word, WordSeparators -&amp;gt; {&quot;\t\t&quot;},
            RecordLists -&amp;gt; True
        ];&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We can filter out non-operators using the Class/Affix column. Let’s look at the unique values in that column.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-wolfram&quot; data-lang=&quot;wolfram&quot;&gt;In[1]:= Union[Select[chars, Length[#] &amp;gt;= 4 &amp;amp;][[All, 4]]]

Out[1]= {&quot;Alias&quot;, &quot;Auto&quot;, &quot;Close&quot;, &quot;CompoundPrefix&quot;, &quot;Infix&quot;, 
        &quot;InfixOpen&quot;, &quot;LargeOp:Prefix&quot;, &quot;Letter&quot;, &quot;NonBreakingAfterLetter&quot;,
        &quot;NonBreakingBeforeLetter&quot;, &quot;Open&quot;, &quot;Postfix&quot;, &quot;Prefix&quot;, &quot;WhiteSp&quot;}&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;These are the ones we want:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-wolfram&quot; data-lang=&quot;wolfram&quot;&gt;In[1]:= affixes = {&quot;Close&quot;, &quot;CompoundPrefix&quot;, &quot;Infix&quot;, &quot;InfixOpen&quot;,
                &quot;LargeOp:Prefix&quot;, &quot;Open&quot;, &quot;Postfix&quot;, &quot;Prefix&quot;};
        ops = Select[chars, Length[#] &amp;gt;= 4 &amp;amp;&amp;amp; MemberQ[affixes, #[[4]]]&amp;amp;];
        Length[ops]

Out[1]= 337&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The character &lt;code class=&quot;highlighter-rouge&quot;&gt;〚&lt;/code&gt; is the only one listed with affix &lt;code class=&quot;highlighter-rouge&quot;&gt;InfixOpen&lt;/code&gt;, while the other matchfix (circumfix) operators are under &lt;code class=&quot;highlighter-rouge&quot;&gt;Open&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;Close&lt;/code&gt;. Most of them appear to function like parentheses, but their rendering in the frontend is flakey. We also have &lt;code class=&quot;highlighter-rouge&quot;&gt;LargeOp:Prefix&lt;/code&gt; operators like ∑ (&lt;code class=&quot;highlighter-rouge&quot;&gt;\[Sum]&lt;/code&gt;), and then ∇ (&lt;code class=&quot;highlighter-rouge&quot;&gt;\[Del]&lt;/code&gt;), which is the only operator with affix &lt;code class=&quot;highlighter-rouge&quot;&gt;CompoundPrefix&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Of the sources of operators and their precedence, the &lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt; is among the largest, and since it is presumably used by Mathematica internals, you can be sure that it is also the most accurate.&lt;/p&gt;

&lt;p&gt;Mysteriously, however, it nonetheless seems to be wrong about precedence in at least one case that I have found so far: &lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt; gives &lt;code class=&quot;highlighter-rouge&quot;&gt;CircleDot&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;PermutationProduct&lt;/code&gt; the same precedence, but &lt;code class=&quot;highlighter-rouge&quot;&gt;CircleDot&lt;/code&gt; does have a &lt;em&gt;higher&lt;/em&gt; precedence than &lt;code class=&quot;highlighter-rouge&quot;&gt;PermutationProduct&lt;/code&gt; while still being lower than the next highest operator, &lt;code class=&quot;highlighter-rouge&quot;&gt;SmallCircle&lt;/code&gt;. That is to say, at least in v11.3, &lt;code class=&quot;highlighter-rouge&quot;&gt;CircleDot&lt;/code&gt;’s real precedence is &lt;code class=&quot;highlighter-rouge&quot;&gt;606.&lt;/code&gt;, not &lt;code class=&quot;highlighter-rouge&quot;&gt;605.&lt;/code&gt; as it is listed.&lt;/p&gt;

&lt;p&gt;This, my dear readers, is where everyone else who has come this way has stopped looking. Let’s go deeper.&lt;/p&gt;

&lt;h3 id=&quot;systemconvertmlstringdatadumpoperators&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;System`Convert`MLStringDataDump`$Operators&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;The undocumented&lt;sup style=&quot;font-weight:bolder&quot; id=&quot;a3&quot; name=&quot;a3&quot;&gt;&lt;a href=&quot;#undocumented&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; system variable &lt;code class=&quot;highlighter-rouge&quot;&gt;System`Convert`MLStringDataDump`$Operators&lt;/code&gt; is a list of 340 operators without any additional information. The list is only available in the notebook frontend. The undocumented function &lt;code class=&quot;highlighter-rouge&quot;&gt;System`Convert`MLStringDataDump`OperatorQ[]&lt;/code&gt; works by checking membership in this list.&lt;/p&gt;

&lt;p&gt;This is the only list, excluding the documentation and &lt;code class=&quot;highlighter-rouge&quot;&gt;WolframLanguageData&lt;/code&gt;, that includes all single and multi-character ASCII operators. As with most other sources, no box operators are included. It also excludes Association brackets, obscure bracketing symbols, many LargeOp:Prefix operators, and a handful of other operators found in &lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We have scoured the documentation, taken a deep dive into Mathematica system files, and explored undocumented features described nowhere else outside of this article save the offices of Wolfram. It may surprise you, then, that there are more operators than we have found so far.&lt;/p&gt;

&lt;h3 id=&quot;the-complement-of-internalsymbolnameq-characters&quot;&gt;The Complement of &lt;code class=&quot;highlighter-rouge&quot;&gt;Internal`SymbolNameQ&lt;/code&gt; Characters&lt;/h3&gt;

&lt;p&gt;Our strategy in this section is to make a list of every Unicode character in the character range used by Mathematica that is &lt;em&gt;not&lt;/em&gt; a letter, &lt;a href=&quot;https://reference.wolfram.com/language/tutorial/LettersAndLetterLikeForms.html&quot;&gt;letter-like form&lt;/a&gt;, or member of &lt;code class=&quot;highlighter-rouge&quot;&gt;System`Convert`MLStringDataDump`$Operators&lt;/code&gt;, which we asign the shorter alias &lt;code class=&quot;highlighter-rouge&quot;&gt;ops&lt;/code&gt;. Using the definition of &lt;code class=&quot;highlighter-rouge&quot;&gt;LetterLikeQ[]&lt;/code&gt; along with the opaque built-in function &lt;code class=&quot;highlighter-rouge&quot;&gt;Internal`SymbolNameQ[]&lt;/code&gt;, we can search the list of Unicode characters to find the complement of the set of characters we can already categorize. Our search criteria is as follows:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-wolfram&quot; data-lang=&quot;wolfram&quot;&gt;In[1]:= crit[c_] := ! Internal`SymbolNameQ[c] &amp;amp;&amp;amp; ! DigitQ[c] &amp;amp;&amp;amp;  ! 
        StringMatchQ[c, WhitespaceCharacter] &amp;amp;&amp;amp; ! MemberQ[ops, c];&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The following code produces a table of code/character pairs matching the criteria above:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-wolfram&quot; data-lang=&quot;wolfram&quot;&gt;In[1]:= Select[
            Table[{i, FromCharacterCode[i]}, {i, 65535}], 
            crit[#[[2]]]&amp;amp;
        ]&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The result is a bit of a surprise: We get a seemingly random handful of ASCII characters, Association brackets, several of the &lt;code class=&quot;highlighter-rouge&quot;&gt;LargeOp:Prefix&lt;/code&gt; operators that are missing in the other lists along with a small handful of other Unicode operators also from &lt;code class=&quot;highlighter-rouge&quot;&gt;UnicodeCharacters.tr&lt;/code&gt;, and, most interestingly, single character versions of multicharacter box operators that are not in any other source. These box operators are:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;0xf7c0: \), 0xf7c1: \!, 0xf7c2: \@, 0xf7c5: \%, 
0xf7c6: \^, 0xf7c7: \&amp;amp;, 0xf7c8: \*, 0xf7c9: \(, 
0xf7ca: \_, 0xf7cb: \+, 0xf7cc: \/, 0xf7cd: \`&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The list also includes the nonoperator characters &lt;code class=&quot;highlighter-rouge&quot;&gt;0xf767: \[ErrorIndicator]&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;0x2043: \[SkeletonIndicator]&lt;/code&gt;, the ASCII delete character &lt;code class=&quot;highlighter-rouge&quot;&gt;0x007f&lt;/code&gt; (127), the ASCII bell character &lt;code class=&quot;highlighter-rouge&quot;&gt;0x0007&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;0xf3ad&lt;/code&gt;, which is an unassigned noncharacter Unicode codepoint “for private use.”&lt;/p&gt;

&lt;p&gt;Since every other Unicode character is either already identified as an operator or in a set known to exclude operators, any unidentified single character Unicode operators are guaranteed to be in this list. We have found them all.&lt;/p&gt;

&lt;h3 id=&quot;other-operators&quot;&gt;Other “Operators”&lt;/h3&gt;

&lt;p&gt;There are other &lt;em&gt;lexemes&lt;/em&gt;—meaningful strings in the language—that could be considered operators but that do not appear outside of the documentation:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;String-related characters like &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;&lt;/code&gt; and escape characters &lt;code class=&quot;highlighter-rouge&quot;&gt;\n&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;\t&lt;/code&gt;, etc.&lt;/li&gt;
  &lt;li&gt;The character representation operators: &lt;code class=&quot;highlighter-rouge&quot;&gt;\[name]&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;\:nn&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;\.nnnn&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;The number representation operators: &lt;code class=&quot;highlighter-rouge&quot;&gt;^^&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;*^&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;``&lt;/code&gt;, though the single &lt;code class=&quot;highlighter-rouge&quot;&gt;`&lt;/code&gt; character does appear in the previous subsection.&lt;/li&gt;
  &lt;li&gt;The comment matchfix operator &lt;code class=&quot;highlighter-rouge&quot;&gt;(*...*)&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These lexemes are such basic units of the language that they may be processed by Mathematica during or even prior to the lexical analysis phase of the code parsing process similar to how &lt;code class=&quot;highlighter-rouge&quot;&gt;C/C++&lt;/code&gt; compiler drivers preprocess &lt;code class=&quot;highlighter-rouge&quot;&gt;#define&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;#include&lt;/code&gt;, and other preprocessor directives before sending the result to the compiler.&lt;/p&gt;

&lt;p&gt;These sorts of language elements are not unique to Wolfram Language, of course, and language tool authors generally make choices about how to handle them based on their syntactic role within the language and what simplifies the software engineering task.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a name=&quot;opnames&quot;&gt;[1]&lt;/a&gt;: &lt;span style=&quot;font-size:85%&quot;&gt;While this may be a minor complaint, the symbolic names of operators do not always correspond to the function of that name. For example, &lt;code class=&quot;highlighter-rouge&quot;&gt;Infix&lt;/code&gt; is the symbolic name for the ternary operator &lt;code class=&quot;highlighter-rouge&quot;&gt;a~f~b&lt;/code&gt; which evaluates as &lt;code class=&quot;highlighter-rouge&quot;&gt;f[a, b]&lt;/code&gt;, whereas the &lt;code class=&quot;highlighter-rouge&quot;&gt;Infix[]&lt;/code&gt; function is just a function that effects the display of &lt;code class=&quot;highlighter-rouge&quot;&gt;f[a, b]&lt;/code&gt;, writing it in terms of the &lt;code class=&quot;highlighter-rouge&quot;&gt;Infix&lt;/code&gt; ternary operator. Meanwhile, the square brackets operator for function application &lt;code class=&quot;highlighter-rouge&quot;&gt;f[e]&lt;/code&gt; is apparently nameless despite the existence of the &lt;a href=&quot;https://reference.wolfram.com/language/ref/Construct.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Construct[]&lt;/code&gt;&lt;/a&gt; function. &lt;/span&gt; &lt;a href=&quot;#a1&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;mrwizard&quot;&gt;[2]&lt;/a&gt;: &lt;span style=&quot;font-size:85%&quot;&gt;
I have borrowed this code with minimal modifications from Mathematica Stack Exchange user &lt;a href=&quot;https://mathematica.stackexchange.com/a/153753/27662&quot;&gt;Mr. Wizard&lt;/a&gt;.
 &lt;/span&gt; &lt;a href=&quot;#a2&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;undocumented&quot;&gt;[3]&lt;/a&gt;: &lt;span style=&quot;font-size:85%&quot;&gt;
In fact, the only mention of this variable on the public internet appears to be this article.
 &lt;/span&gt; &lt;a href=&quot;#a3&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;</content><author><name>Robert Jacobson</name><email>rljacobson@gmail.com</email></author><category term="Computer science" /><category term="compilers" /><category term="Mathematica" /><summary type="html">Finding All Wolfram Language Operators</summary></entry><entry><title type="html">Defining the Wolfram Language Part 0: The Challenge</title><link href="/defining-the-wolfram-language-part-0-the-challenge" rel="alternate" type="text/html" title="Defining the Wolfram Language Part 0: The Challenge" /><published>2018-07-02T20:14:00-04:00</published><updated>2018-07-02T20:14:00-04:00</updated><id>/defining-the-wolfram-language-part-0-the-challenge</id><content type="html" xml:base="/defining-the-wolfram-language-part-0-the-challenge">&lt;p&gt;&lt;em&gt;What is the definition of the Wolfram Language?&lt;/em&gt; This is the first in a series of articles attempting to answer this question.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;What &lt;em&gt;is&lt;/em&gt; a programming language, really? Most programming languages in production use, like C++ or Javascript, have some kind of formal specification that defines the language that each implementation (e.g. each compiler or web browser) must adhere to. Many languages also have a “reference implementation” of the language whose source code could be studied, at least in principle, to determine precisely how the language works. &lt;a href=&quot;https://www.wolfram.com/language/&quot;&gt;Wolfram Language&lt;/a&gt;, the programming language of &lt;a href=&quot;http://www.wolfram.com/mathematica/&quot;&gt;Mathematica&lt;/a&gt;, has neither of these things.&lt;/p&gt;

&lt;p&gt;But what if it did? What would a language specification look like for Wolfram Language? If you were tasked with writing the spec, how would you do it, and what choices would you make? This is how we shall imagine ourselves throughout this series of articles: as language documentarians reconstructing the syntactic and semantic structure of Wolfram Language from its usage.&lt;/p&gt;

&lt;p&gt;Some of the information in this series grew out of my work on &lt;a href=&quot;https://github.com/rljacobson/FoxySheep&quot;&gt;FoxySheep&lt;/a&gt;, an open source parser for the Wolfram Language. Parts &lt;a href=&quot;defining-the-wolfram-language-part-1-finding-operators&quot;&gt;1&lt;/a&gt; and &lt;a href=&quot;defining-the-wolfram-language-part-2-operator-properties&quot;&gt;2&lt;/a&gt; began life as an answer I submitted to &lt;a href=&quot;https://mathematica.stackexchange.com/a/180033/27662&quot;&gt;mathematica.stackexchange.com&lt;/a&gt;. I try to keep the answer up to date.&lt;/p&gt;

&lt;h2 id=&quot;the-impossibility-problem&quot;&gt;The Impossibility Problem&lt;/h2&gt;

&lt;p&gt;At the end of the day, there just is no public language specification for Wolfram Language. We might say that the language is &lt;em&gt;defined to be&lt;/em&gt; whatever Mathematica does. But this “definition” leaves a lot to be desired. If we want to produce a formal language spec from its implementation in Mathematica alone, we are faced with some significant challenges:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It requires access to a proprietary, expensive piece of software.&lt;/li&gt;
  &lt;li&gt;The language evolves from one version of Mathematica to the next.&lt;/li&gt;
  &lt;li&gt;It is not clear how to determine—or even discover—some language features using only the language itself.&lt;/li&gt;
  &lt;li&gt;It is labor-intensive. We shall see in Part 1 that Wolfram Language has about 400 different operators, all of which need to be rigorously described.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Most importantly, it is not clear that this “definition” is even self-consistent. (&lt;em&gt;Spoiler alert: It isn’t.&lt;/em&gt;) In other words, what Mathematica does on the command line may differ from what it does in the notebook, which may differ from the behavior of &lt;code class=&quot;highlighter-rouge&quot;&gt;ToExpression&lt;/code&gt; and related functions, all of which may differ from the official documentation, which may itself be internally inconsistent—and all of this in just a single version of Mathematica running on a single platform.&lt;/p&gt;

&lt;p&gt;We are also faced with a demarcation problem: Where does the &lt;em&gt;language&lt;/em&gt; of Wolfram Language end and the various non-essential libraries and APIs that ship with Mathematica begin? Surely, control structures like &lt;a href=&quot;https://reference.wolfram.com/language/ref/If.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;If&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://reference.wolfram.com/language/ref/While.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;While&lt;/code&gt;&lt;/a&gt; belong to the language, while functions like &lt;a href=&quot;https://reference.wolfram.com/language/ref/WordCloud.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;WordCloud&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://reference.wolfram.com/language/ref/WikipediaSearch.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;WikipediaSearch&lt;/code&gt;&lt;/a&gt; are clearly not essential language features. But what about &lt;a href=&quot;https://reference.wolfram.com/language/ref/Plot.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Plot&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;https://reference.wolfram.com/language/ref/HistogramTransform.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;HistogramTransform&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;https://reference.wolfram.com/language/ref/TimeValue.html&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;TimeValue&lt;/code&gt;&lt;/a&gt;? Are the mathematical functions like &lt;code class=&quot;highlighter-rouge&quot;&gt;Sin&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Integrate&lt;/code&gt; essential features of the language? Some languages include a standard library of functions that is considered part of the language standard. Should there be a standard library for Wolfram Language, and if so, which functions should belong to it?&lt;/p&gt;

&lt;p&gt;The demarcation problem extends to what might be considered implementation details. For example, &lt;a href=&quot;https://reference.wolfram.com/language/tutorial/VariablesInPureFunctionsAndRules.html&quot;&gt;Mathematica renames “local” variables&lt;/a&gt; within an inner scope to unique names to avoid potential name collisions. There presumably needs to be some kind of mechanism to maintain λ calculus semantics for pure functions, but maybe which mechanism is employed is an implementation detail rather than part of the hypothetical language spec.&lt;/p&gt;

&lt;p&gt;We will have more to say about the technological and philosophical implications of these questions later in this series.&lt;/p&gt;

&lt;h2 id=&quot;why-do-we-care&quot;&gt;Why do we care?&lt;/h2&gt;

&lt;p&gt;Different from a user manual intended to teach someone how to use the language, a formal specification is a complete, precise technical definition of what makes up a valid program in the language, and, perhaps counterintuitively, is usually not very helpful in learning how to program in the language. The quality of Mathematica’s user manual is generally considered among the highest in the industry. What, then, is the use of a formal specification for Wolfram Language?&lt;/p&gt;

&lt;p&gt;First, a formal specification is essential for someone wishing to &lt;em&gt;implement&lt;/em&gt; the language. This is relevant to only a handful of people in the world who write compiler tools, but the value of the work done by these few people is trememdous, as their tools may be used by many thousands of people.&lt;sup name=&quot;a1&quot; id=&quot;a1&quot;&gt;&lt;a href=&quot;#intellij&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Second, it is common for advanced users of Wolfram Language (Mathematica) to want to employ “custom” operators for their own purposes. The language has many operators for a variety of uses, including operators that intentionally have no built-in meaning so that users can use them for their own purposes. New Mathematica users are often puzzled why their code behaves differently than they expect due to incorrect assumptions about the precedence of operators, that is, the order in which the operations are performed. More advanced users often wish to know the precedence and other properties of operators so they can select an operator with no built-in meaning that behaves precisely according to whatever purpose is desired.&lt;/p&gt;

&lt;p&gt;Finally, the study of programming languages in general is a rewarding and rich experience that takes one on a veritable tour of nearly every corner of computer science and software engineering. Students of programming languages have much to learn from comparing and contrasting different languages and implementations. Wolfram Language is an interesting language for a variety of reasons: it shares features of LISP and ML yet supports imperative programming; it supports both dynamic and lexical scoping, namespaces (contexts), and modules; it is untyped/weakly typed; and so on.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The creator of Mathematica Stephen Wolfram and his son Conrad Wolfram were consultants for the film Arrival.&lt;sup name=&quot;a2&quot; id=&quot;a2&quot;&gt;&lt;a href=&quot;#arrival&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; In the film, linguists are faced with the challenge of deciphering an alien language completely unlike any other known language in order to communicate with alien visitors. Stephen and Conrad were asked to imagine what it would look like to try to accomplish this task. For the characters in the film, the task seems at first impossible, but the benefit was potentially tremendous: the sharing of knowledge.&lt;/p&gt;

&lt;p&gt;Rigorously describing a programming language with only a single proprietary implementation is not quite as dramatic, and Wolfram Language is hardly an alien language. Despite the heavy-handedness of the analogy, the benefits of a mutually comprehensible language is the same nonetheless: information can be exchanged. A technical description of Wolfram Language would enable the sharing of knowledge among anyone or anything that can speak Wolfram Language: human beings, compiler tools, third party software, and, importantly, Mathematica itself.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a name=&quot;intellij&quot;&gt;[1]&lt;/a&gt;:
A great example of this is the &lt;a href=&quot;http://wlplugin.halirutan.de/&quot;&gt;Mathematica plugin for the IntelliJ suite of IDEs from JetBrains&lt;/a&gt;. The Mathematica plugin is essentially the work of one person, Patrick Scheibe, but is enjoyed by tens of thousands of users. &lt;a href=&quot;#a1&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&quot;arrival&quot;&gt;[2]&lt;/a&gt;: Stephan Wolfram, “&lt;a href=&quot;http://blog.stephenwolfram.com/2016/11/quick-how-might-the-alien-spacecraft-work/&quot;&gt;Quick, How Might the Alien Spacecraft Work?&lt;/a&gt;,” blog post, November 10, 2016. &lt;a href=&quot;#a2&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;</content><author><name>Robert Jacobson</name><email>rljacobson@gmail.com</email></author><category term="Computer science" /><category term="compilers" /><category term="Mathematica" /><summary type="html">What is the definition of the Wolfram Language? This is the first in a series of articles attempting to answer this question.</summary></entry><entry><title type="html">The grammar of mathematical expressions</title><link href="/the-grammar-of-mathematical-expressions" rel="alternate" type="text/html" title="The grammar of mathematical expressions" /><published>2015-01-28T22:31:00-05:00</published><updated>2015-01-28T22:31:00-05:00</updated><id>/the-grammar-of-mathematical-expressions</id><content type="html" xml:base="/the-grammar-of-mathematical-expressions">&lt;p&gt;Using computers to do automatic translation has a long and rich history in computer science. A course in compiler construction is a veritable survey of topics in computer science running the gamut from formal languages to data structures and algorithms to Hopfcroft’s algorithm to minimize deterministic automata. One of the first things a student learns in a compiler construction course is how to formally describe the grammar of a language using (extended) Backus–Naur form (EBNF).&lt;!--more--&gt; This article will assume a passing familiarity with EBNF notation.&lt;/p&gt;

&lt;h2 id=&quot;a-simple-grammar-for-math-expressions&quot;&gt;A simple grammar for math expressions.&lt;/h2&gt;

&lt;p&gt;An exercise every compiler construction student is given is to construct a grammar for simple mathematical expressions. This exercise is particularly easy with &lt;a href=&quot;http://www.antlr.org&quot;&gt;ANTLR 4&lt;/a&gt;, a lexer and parser generator that can accept grammars than many other compiler tools would reject. Here is an ANTLR 4 grammar for simple math expressions.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-antlr&quot; data-lang=&quot;antlr&quot;&gt;expr
	:	INT //numbers
	|	ID  //variables
	|	'(' expr ')'  //grouping with parentheses
	|	&amp;lt;assoc=right&amp;gt; expr '^' expr //exponentiation
	|	('+' | '-') expr	//unary plus/minus
	|	expr ('/' | '*') expr	//explicit division/multiplication
	|	expr ('+' | '-') expr	//addition/subtraction
	;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;For the input &lt;code class=&quot;highlighter-rouge&quot;&gt;4*x^2 - 3*x + -2&lt;/code&gt; this grammar gives the following parse tree.&lt;/p&gt;

&lt;p&gt;&lt;img style=&quot;width:auto;&quot; src=&quot;assets/images/posts/MathGrammar/simple_parse_tree.png&quot; width=&quot;300&quot; height=&quot;241&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ANTLR conveniently handles the order of operations for us by giving precedence to the production alternative that comes first: the earlier the alternative, the higher the precedence of the operator. Also, the right associativity of exponentiation is taken care of by the directive &amp;lt;assoc=right&amp;gt;. Piece of cake. And it’s easy to expand this grammar to include other operators, like the postfix factorial (!) for example.&lt;/p&gt;

&lt;h2 id=&quot;the-grammatical-challenge-of-implicit-multiplication&quot;&gt;The grammatical challenge of implicit multiplication&lt;/h2&gt;

&lt;p&gt;Mathematicians don’t like to write an explicit symbol for multiplication unless we’re compelled to. We prefer to write &lt;code class=&quot;highlighter-rouge&quot;&gt;4x^2 - 3x + -2&lt;/code&gt; instead of &lt;code class=&quot;highlighter-rouge&quot;&gt;4*x^2 - 3*x + -2&lt;/code&gt;. We might naively modify our grammar as follows.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-antlr&quot; data-lang=&quot;antlr&quot;&gt;expr
	:	INT //numbers
	|	ID  //variables
	|	'(' expr ')' 	//grouping with parentheses
	|	&amp;lt;assoc=right&amp;gt; expr '^' expr 	//exponentiation
	|	('+' | '-') expr 	//unary plus/minus
	|	expr '/' expr 	//division
	|	expr '*'? expr 	//explicit multiplication
	|	expr ('+' | '-') expr 	//addition/subtraction
	;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt; after the &lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt; indicates that the &lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt; symbol is optional–it can be omitted. But this doesn’t work as expected! This grammar parses &lt;code class=&quot;highlighter-rouge&quot;&gt;7 + 3&lt;/code&gt; as &lt;code class=&quot;highlighter-rouge&quot;&gt;7*(+3)&lt;/code&gt;, which is not what we want. Splitting implicit multiplication off as a seperate alternative appears to solve this problem.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-antlr&quot; data-lang=&quot;antlr&quot;&gt;expr
	:	INT //numbers
	|	ID  //variables
	|	'(' expr ')' //grouping with parentheses
	|	&amp;lt;assoc=right&amp;gt; expr '^' expr //exponentiation
	|	('+' | '-') expr	//unary plus/minus
	|	expr '/' expr		//division
	|	expr '*' expr	//explicit multiplication
	|	expr expr	//implicit multiplication
	|	expr ('+' | '-') expr	//addition/subtraction
	;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;But now we have a new problem: implicit multiplication does not respect order of operations. This grammar generates the following parse tree for the input &lt;code class=&quot;highlighter-rouge&quot;&gt;4x+3&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img style=&quot;width:auto;&quot; src=&quot;assets/images/posts/MathGrammar/modified_parse_tree.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What’s going on? Precedence only applies to tokens, e.g. operator symbols, and our implicit multiplication alternative has no operator. (This wrong solution is common. You’ll see people on the web wondering why adding implicit multiplication doesn’t respect operator precedence.)&lt;/p&gt;

&lt;h2 id=&quot;the-solution&quot;&gt;The solution&lt;/h2&gt;

&lt;p&gt;But we can enforce order of operations by having a hierarchy of production rules like the following general pattern [1].&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-antlr&quot; data-lang=&quot;antlr&quot;&gt;type_variable: ...

type_primary: type_variable
              | ...

type_secondary: type_primary
              | ...

type_tertiary: type_secondary
              | ...

type_expression: type_tertiary
              | ...&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;So instead of relying on ANTLR to determine precedence according to the order of each alternative, we bake it into the grammar itself. We might rewrite our math expression grammar as follows [2].&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-antlr&quot; data-lang=&quot;antlr&quot;&gt;term
	:	INT
	|	ID
	|	'(' expr ')' //parentheses
	;

//Implicit multiplication
factor
	:	term
	|	&amp;lt;assoc=right&amp;gt; term '^' factor
	|	term factor
	;

//Unary minus/plus
prefix
	:	factor
	|	('+' | '-') prefix //unary plus/minus
	;

//Explicit multiplication/division
multdiv
	:	prefix
	|	multdiv '/' prefix //division
	|	multdiv '*' prefix //explicit multiplication
	;

expr
	:	multdiv
	|	expr ('+' | '-') multdiv //addition/subtraction
	;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Notice I awkwardly included exponentiation in the factor production relying on ANTLR to implicitly determine its precedence over implicit multiplication. This suggests that the above grammar is overcomplicated, that is, we can collapse much of this hierarchy and let ANTLR do some of the work. Here is our final grammar.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-antlr&quot; data-lang=&quot;antlr&quot;&gt;term
	:	LEAF
	|	'(' expr ')'	//parentheses
	;

//Implicit multiplication
factor
	:	term
	|	&amp;lt;assoc=right&amp;gt; term '^' factor
	|	term factor
	;

//Unary minus/plus
expr
	:	factor
	|	('+' | '-') expr //unary plus/minus
	|	expr '/' expr	//division
	|	expr '*' expr	//explicit multiplication
	|	expr ('+' | '-') expr	//addition/subtraction
	;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;And the parse tree for &lt;code class=&quot;highlighter-rouge&quot;&gt;4x^2 - 3x + -2&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img style=&quot;width:auto;&quot; src=&quot;assets/images/posts/MathGrammar/final_parse_tree.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Success!&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;You can see that there is a reason most languages–even computer algebra systems–require an explicit multiplication symbol. Requiring a &lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt; is a small price to pay for a simpler language grammar.&lt;/p&gt;

&lt;p&gt;This is a great example of how tweaking a very simple problem can sometimes produce a very challenging problem. As a math teacher I really like this example, because there is so much opportunity to teach. We review the concept of order of operations and how order of operations works in mathematics, and we learn about a strategy for dealing with order of operations in formal grammars. All of this is done from a very applied, very real-world problem that the students can value.&lt;/p&gt;

&lt;p&gt;But the punchline shouldn’t be that writing a formal grammar for a math expression parser is hard. Rather, writing grammars in general is hard, language itself is hard. This challenge came up in the context of math expressions, but it could just as easily come up in the context of parsing any language. John Levine [3] calls writing a grammar with error recovery a “black art,” Cooper and Torczon [4] call compiler construction an “art and science,” Michael L. Scott [5] refers to the “art” of language design and cites Donald Knuth [6] as suggesting programming can be regarded as the “art of telling another human being what one wants the computer to do.” I like to think that what these heavyweights are telling us is that we should embrace the difficulty as something beautiful.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;notes&quot;&gt;Notes&lt;/h4&gt;

&lt;p&gt;[1]: This standard pattern is described by Laurence Finston at &lt;a href=&quot;http://lists.gnu.org/archive/html/help-bison/2005-08/msg00004.html&quot;&gt;http://lists.gnu.org/archive/html/help-bison/2005-08/msg00004.html&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[2]: This implementation of the general pattern is essentially stackoverflow user rici’s, &lt;a href=&quot;http://stackoverflow.com/questions/12875573/how-can-i-have-an-implicit-multiplication-rule-with-bison&quot;&gt;http://stackoverflow.com/questions/12875573/how-can-i-have-an-implicit-multiplication-rule-with-bison&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[3]: John Levine, &lt;em&gt;flex and bison&lt;/em&gt;, O’Reilly, 2009.&lt;/p&gt;

&lt;p&gt;[4]: Keith D. Cooper and Linda Torczon, &lt;em&gt;Engineering a Compiler&lt;/em&gt;, second edition, Morgan Kaufmann, 2012.&lt;/p&gt;

&lt;p&gt;[5]: Michael L. Scott, &lt;em&gt;Programming Language Pragmatics&lt;/em&gt;, third edition, Morgan Kaufmann, 2009.&lt;/p&gt;

&lt;p&gt;[6]: Donald Knuth, “Literate programming,” &lt;em&gt;The Computer Journal&lt;/em&gt;, 27(2):97-111, May 1984.&lt;/p&gt;</content><author><name>Robert Jacobson</name><email>rljacobson@gmail.com</email></author><category term="Computer science" /><category term="compilers" /><summary type="html">Using computers to do automatic translation has a long and rich history in computer science. A course in compiler construction is a veritable survey of topics in computer science running the gamut from formal languages to data structures and algorithms to Hopfcroft’s algorithm to minimize deterministic automata. One of the first things a student learns in a compiler construction course is how to formally describe the grammar of a language using (extended) Backus–Naur form (EBNF). This article will assume a passing familiarity with EBNF notation.</summary></entry><entry><title type="html">Using Mathematica From Python</title><link href="/using-mathematica-from-python" rel="alternate" type="text/html" title="Using Mathematica From Python" /><published>2014-12-10T22:27:00-05:00</published><updated>2014-12-10T22:27:00-05:00</updated><id>/using-mathematica-from-python</id><content type="html" xml:base="/using-mathematica-from-python">&lt;p&gt;In which I show you how to programmatically interface with a Mathematica kernel from Python.&lt;!--more--&gt;&lt;/p&gt;

&lt;h2 id=&quot;mathematica-python-and-scientific-computation&quot;&gt;Mathematica, Python, and Scientific Computation&lt;/h2&gt;

&lt;p&gt;Mathematica is the flagship product of &lt;a href=&quot;http://www.wolfram.com/mathematica/&quot;&gt;Wolfram Research&lt;/a&gt;. It’s a very sophisticated computer algebra system with the best notebook interface on the market if you ask me. It provides the computational power to &lt;a href=&quot;http://www.wolframalpha.com/&quot;&gt;WolframAlpha&lt;/a&gt; and is available on “thousands of colleges and universities in over 50 countries” according to Wolfram Research’s ad copy. Unfortunately Mathematica is not open source and comes with a hefty price tag, but your institution might have a site license that allows you to install it on your personal computer.&lt;/p&gt;

&lt;p&gt;Python has gained a lot of ground in the scientific computation space. With packages like &lt;a href=&quot;http://www.scipy.org&quot;&gt;SciPy&lt;/a&gt; and SymPy and the comprehensive computer algebra system &lt;a href=&quot;http://www.sagemath.org&quot;&gt;Sage&lt;/a&gt;, Python has access to very sophisticated computational abilities. You know what would be really great, though? If we could interact with a Mathematica kernel directly from our Python code.&lt;/p&gt;

&lt;h2 id=&quot;the-good-news&quot;&gt;The Good News&lt;/h2&gt;

&lt;p&gt;It turns out we can. Mathematica ships with something called MathLink that allows developers of C and C++ (and some other languages) to communicate with a Mathematical kernel programmatically. If you poke around in the Mathematica installation directory you will discover Python bindings for MathLink and a couple of example programs.&lt;/p&gt;

&lt;h2 id=&quot;the-bad-newsand-a-fix&quot;&gt;The Bad News—And a Fix&lt;/h2&gt;

&lt;p&gt;Unfortunately the MathLink Python bindings are undocumented, unsupported, and &lt;em&gt;very&lt;/em&gt; outdated. Here I show you how I got it working on my system running Mac OS X Yosemite, Mathematica 10.0, and Python 2.7. It’s not too hard. I’ll assume you have the usual &lt;a href=&quot;http://www.sagemath.org/doc/installation/source.html#section-macprereqs&quot;&gt;command line developer tools&lt;/a&gt; installed.&lt;/p&gt;

&lt;p&gt;First we locate the necessary MathLink library, namely libMLi3.a. On my system it is found here:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;/Applications/Mathematica.app/SystemFiles/Links/MathLink/DeveloperKit/MacOSX-x86-64/CompilerAdditions/AlternativeLibraries&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;I’m using the “AlternativeLibraries” version as per the README file located in that directory. We’ll also need the mathlink.h header file here:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;/Applications/Mathematica.app/SystemFiles/Links/MathLink/DeveloperKit/MacOSX-x86-64/CompilerAdditions&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now we find the MathLink Python bindings and example code:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;/Applications/Mathematica.app/SystemFiles/Links/Python&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Since we will be editing these files, go ahead and copy them to a folder in which to work. That way, if we mess something up we have a backup of the original files.&lt;/p&gt;

&lt;p&gt;One of those files, the setup.py file, uses Python’s distutils facility to compile and install the Python MathLink bindings extension to our Python environment’s site-packages directory. Edit the file to reflect your mathematica version (this might not be strictly necessary):&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;mathematicaversion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;10.0&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now find your platform in the &lt;code class=&quot;highlighter-rouge&quot;&gt;if-elif&lt;/code&gt; block (in my case “darwin”) and edit &lt;code class=&quot;highlighter-rouge&quot;&gt;include_dirs&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;library_dirs&lt;/code&gt; to be the location of the mathlink.h header file and the library file libMLi3.a respectively. Here’s what that piece of code now looks like for my system:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'darwin'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;platform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;setup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mathlink&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pythonlinkversion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ext_modules&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;Extension&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;mathlink&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mathlink.c&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;include_dirs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/Applications/Mathematica.app/SystemFiles/Links/MathLink/DeveloperKit/MacOSX-x86-64/CompilerAdditions/AlternativeLibraries&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;library_dirs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/Applications/Mathematica.app/SystemFiles/Links/MathLink/DeveloperKit/MacOSX-x86-64/CompilerAdditions/AlternativeLibraries&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;libraries&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;MLi3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The Python extention is mathlink.c. We need to make a minor adjustment to mathlink.c by defining &lt;code class=&quot;highlighter-rouge&quot;&gt;MLINTERFACE&lt;/code&gt; to be 3 &lt;em&gt;before&lt;/em&gt; we include the mathlink.h header file:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span class=&quot;cp&quot;&gt;#define MLINTERFACE 3
#include &quot;mathlink.h&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;That’s it for the Python bindings! Let’s compile and install:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;python setup.py build
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;python setup.py install&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You should now be able to run the example script with the following command:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;python textfrontend.py &lt;span class=&quot;nt&quot;&gt;-linkname&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;math -mathlink&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;If you look inside textfrontend.py you’ll find a strange attempt by the author to add the Mathematica bin directory to the path. Since the &lt;code class=&quot;highlighter-rouge&quot;&gt;math&lt;/code&gt; command is already in my path, this line is unnecessary. The script sets up the mathlink connection using the -linkname argument. Consider these things as opportunities for improvement as you monkey with this example code.&lt;/p&gt;

&lt;p&gt;Now go write some good Python code!&lt;/p&gt;</content><author><name>Robert Jacobson</name><email>rljacobson@gmail.com</email></author><category term="Computer science" /><category term="Programming" /><category term="Mathematica" /><category term="Python" /><summary type="html">In which I show you how to programmatically interface with a Mathematica kernel from Python.</summary></entry><entry><title type="html">Platonic Solids and the School of Athens</title><link href="/platonic-solids-and-the-school-of-athens" rel="alternate" type="text/html" title="Platonic Solids and the School of Athens" /><published>2014-07-25T22:57:00-04:00</published><updated>2014-07-25T22:57:00-04:00</updated><id>/platonic-solids-and-the-school-of-athens</id><content type="html" xml:base="/platonic-solids-and-the-school-of-athens">&lt;h2 id=&quot;euclid-in-the-school-of-athens&quot;&gt;Euclid in The School of Athens&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://lh4.googleusercontent.com/-UC44EGZXUfQ/U9LVe6BOFeI/AAAAAAAATQ4/Z3iy0xM4NVc/w723-h542-no/IMG_0537+2.JPG&quot; alt=&quot;Me in front of The School of Athens&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is a very special fresco painting by Italian Renaissance artist Raphael in the Vatican Museum called &lt;a href=&quot;http://en.wikipedia.org/wiki/The_School_of_Athens&quot;&gt;The School of Athens&lt;/a&gt;. It depicts the great philosophers of ancient Greece, famously with Plato pointing up and Aristotle pointing down.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://lh5.googleusercontent.com/-s0vNpq-G4bY/U9LVWPrGeGI/AAAAAAAATQk/GWshULXKBsQ/w527-h502-no/IMG_0537.JPG&quot; alt=&quot;Detail of previous&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Just to the right of me you can see Euclid doing some geometry on a tablet. Euclid’s contribution to mathematics is of course well known. The significance of his surviving masterpiece &lt;em&gt;The Elements&lt;/em&gt; cannot be overstated, though the results and proofs collected in &lt;em&gt;The Elements&lt;/em&gt; are not due entirely (or even mostly) to Euclid himself. One of the major results in &lt;em&gt;The Elements&lt;/em&gt; is the construction of the five so-called Platonic solids and the proof that there are only five such solids. In fact, some commentators suggest that the establishment of this fact is the primary motivation of &lt;em&gt;The Elements&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;A platonic solid is a solid having faces all of which are the same regular polygon and with the same number of faces meeting at each vertex. If $p$ is the number of edges of each face and $q$ is the number of faces at each vertex, then each solid is uniquely identified by the ordered pair ${p, q}$ (called the Schläfli symbol). Here they all are:&lt;/p&gt;

&lt;table class=&quot;wikitable sortable jquery-tablesorter&quot;&gt;

&lt;thead&gt;&lt;tr&gt;
&lt;th colspan=&quot;2&quot; class=&quot;headerSort&quot; tabindex=&quot;0&quot; role=&quot;columnheader button&quot; title=&quot;Sort ascending&quot;&gt;Polyhedron
&lt;/th&gt;
&lt;th class=&quot;headerSort&quot; tabindex=&quot;0&quot; role=&quot;columnheader button&quot; title=&quot;Sort ascending&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Vertex_(geometry)&quot; title=&quot;Vertex (geometry)&quot;&gt;Vertices&lt;/a&gt;
&lt;/th&gt;
&lt;th class=&quot;headerSort&quot; tabindex=&quot;0&quot; role=&quot;columnheader button&quot; title=&quot;Sort ascending&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Edge_(geometry)&quot; title=&quot;Edge (geometry)&quot;&gt;Edges&lt;/a&gt;
&lt;/th&gt;
&lt;th class=&quot;headerSort&quot; tabindex=&quot;0&quot; role=&quot;columnheader button&quot; title=&quot;Sort ascending&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Face_(geometry)&quot; title=&quot;Face (geometry)&quot;&gt;Faces&lt;/a&gt;
&lt;/th&gt;
&lt;th class=&quot;headerSort&quot; tabindex=&quot;0&quot; role=&quot;columnheader button&quot; title=&quot;Sort ascending&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Schl%C3%A4fli_symbol&quot; title=&quot;Schläfli symbol&quot;&gt;Schläfli symbol&lt;/a&gt;
&lt;/th&gt;
&lt;th class=&quot;headerSort&quot; tabindex=&quot;0&quot; role=&quot;columnheader button&quot; title=&quot;Sort ascending&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Vertex_configuration&quot; title=&quot;Vertex configuration&quot;&gt;Vertex configuration&lt;/a&gt;
&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;
&lt;tr align=&quot;center&quot;&gt;
&lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Tetrahedron&quot; title=&quot;Tetrahedron&quot;&gt;tetrahedron&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/File:Tetrahedron.svg&quot; class=&quot;image&quot; title=&quot;Tetrahedron&quot;&gt;&lt;img alt=&quot;Tetrahedron&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Tetrahedron.svg/50px-Tetrahedron.svg.png&quot; width=&quot;50&quot; height=&quot;47&quot; srcset=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Tetrahedron.svg/75px-Tetrahedron.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Tetrahedron.svg/100px-Tetrahedron.svg.png 2x&quot; data-file-width=&quot;570&quot; data-file-height=&quot;540&quot; /&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;{3, 3}&lt;/td&gt;
&lt;td&gt;3.3.3
&lt;/td&gt;&lt;/tr&gt;
&lt;tr align=&quot;center&quot;&gt;
&lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Cube&quot; title=&quot;Cube&quot;&gt;cube&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/File:Hexahedron.svg&quot; class=&quot;image&quot; title=&quot;Hexahedron (cube)&quot;&gt;&lt;img alt=&quot;Hexahedron (cube)&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Hexahedron.svg/50px-Hexahedron.svg.png&quot; width=&quot;50&quot; height=&quot;56&quot; srcset=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Hexahedron.svg/75px-Hexahedron.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Hexahedron.svg/100px-Hexahedron.svg.png 2x&quot; data-file-width=&quot;540&quot; data-file-height=&quot;600&quot; /&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;{4, 3}&lt;/td&gt;
&lt;td&gt;4.4.4
&lt;/td&gt;&lt;/tr&gt;
&lt;tr align=&quot;center&quot;&gt;
&lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Octahedron&quot; title=&quot;Octahedron&quot;&gt;octahedron&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/File:Octahedron.svg&quot; class=&quot;image&quot; title=&quot;Octahedron&quot;&gt;&lt;img alt=&quot;Octahedron&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/0/07/Octahedron.svg/50px-Octahedron.svg.png&quot; width=&quot;50&quot; height=&quot;50&quot; srcset=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/0/07/Octahedron.svg/75px-Octahedron.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/0/07/Octahedron.svg/100px-Octahedron.svg.png 2x&quot; data-file-width=&quot;840&quot; data-file-height=&quot;832&quot; /&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;{3, 4}&lt;/td&gt;
&lt;td&gt;3.3.3.3
&lt;/td&gt;&lt;/tr&gt;
&lt;tr align=&quot;center&quot;&gt;
&lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Regular_dodecahedron&quot; title=&quot;Regular dodecahedron&quot;&gt;dodecahedron&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/File:Dodecahedron.svg&quot; class=&quot;image&quot; title=&quot;Dodecahedron&quot;&gt;&lt;img alt=&quot;Dodecahedron&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Dodecahedron.svg/50px-Dodecahedron.svg.png&quot; width=&quot;50&quot; height=&quot;50&quot; srcset=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Dodecahedron.svg/75px-Dodecahedron.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Dodecahedron.svg/100px-Dodecahedron.svg.png 2x&quot; data-file-width=&quot;300&quot; data-file-height=&quot;300&quot; /&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;{5, 3}&lt;/td&gt;
&lt;td&gt;5.5.5
&lt;/td&gt;&lt;/tr&gt;
&lt;tr align=&quot;center&quot;&gt;
&lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Regular_icosahedron&quot; title=&quot;Regular icosahedron&quot;&gt;icosahedron&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/File:Icosahedron.svg&quot; class=&quot;image&quot; title=&quot;Icosahedron&quot;&gt;&lt;img alt=&quot;Icosahedron&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/Icosahedron.svg/50px-Icosahedron.svg.png&quot; width=&quot;50&quot; height=&quot;48&quot; srcset=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/Icosahedron.svg/75px-Icosahedron.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/Icosahedron.svg/100px-Icosahedron.svg.png 2x&quot; data-file-width=&quot;385&quot; data-file-height=&quot;370&quot; /&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;{3, 5}&lt;/td&gt;
&lt;td&gt;3.3.3.3.3
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;tfoot&gt;&lt;/tfoot&gt;&lt;/table&gt;
&lt;p&gt;Table Source: &lt;a href=&quot;http://en.wikipedia.org/wiki/Platonic_solid&quot;&gt;Platonic Solid on Wikipedia&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;symmetry&quot;&gt;Symmetry&lt;/h2&gt;

&lt;p&gt;Each platonic solid has a high degree of symmetry. By rotating a given solid along various axes, one can obtain exactly the same solid in the same orientation. These rotation operations under which the solid is invariant form a special kind of algebraic group called a symmetric group.&lt;/p&gt;

&lt;p&gt;The dual of a regular polyhedron having $p$ vertices and $q$ faces is the solid having $q$ vertices and $p$ faces–one simply interchanges the roles of the vertices and edges to obtain the dual. Notice that the dual of each platonic solid is another platonic solid. This is such a satisfying fact to me.&lt;/p&gt;

&lt;h2 id=&quot;leaving-the-school-of-athens&quot;&gt;Leaving the School of Athens&lt;/h2&gt;

&lt;p&gt;Of course there are many other interesting facts about the platonic solids. For example, the Golden Ratio $\phi:=\frac{1+\sqrt{5}}{2}$ is related to the platonic solids. You will have to check out Wikipedia for the details.&lt;/p&gt;

&lt;p&gt;That the ancients proved there are only five platonic solids does not diminish how mathematically interesting this fact is to me. A natural question to ask is, how many platonic solids (that is, platonic polytopes) are there in four dimensions? It turns out there are six. (One of them is trivial to find: Just add another point to the tetrahedron to form a 4-simplex.) But what is really interesting is that in every dimension greater than four there are only three platonic solids. So what is special about dimensions three and four?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://lh6.googleusercontent.com/-A94MoG2qZf0/U9LVeJVM5CI/AAAAAAAATQ0/U-FMEk0sxio/w377-h502-no/IMG_0538.jpg&quot; alt=&quot;enter image description here&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As I walked toward the exit of the room with The School of Athens fresco I found a painting of two platonic skeletons in a closet. It is fitting to find these geometric objects so close by the ancient Greek’s who studied their mathematical properties so extensively.&lt;/p&gt;</content><author><name>Robert Jacobson</name><email>rljacobson@gmail.com</email></author><category term="Mathematics" /><category term="Art" /><category term="Geometry" /><summary type="html">Euclid in The School of Athens</summary></entry><entry><title type="html">How Springer sent me to collections for adopting their textbook.</title><link href="/how-springer-sent-me-to-collections-for-adopting-their-textbook" rel="alternate" type="text/html" title="How Springer sent me to collections for adopting their textbook." /><published>2014-04-17T20:52:00-04:00</published><updated>2014-04-17T20:52:00-04:00</updated><id>/how-springer-sent-me-to-collections-for-adopting-their-textbook</id><content type="html" xml:base="/how-springer-sent-me-to-collections-for-adopting-their-textbook">&lt;p&gt;The story begins with one of those little mundane activities that fill every professor’s day. Right before the spring semester began I was evaluating various textbook options for the next time I teach undergraduate real analysis. Stephen Abbott’s &lt;em&gt;Understanding Analysis&lt;/em&gt; published by Springer seemed to be exactly the kind of book I was looking for.&lt;!--more--&gt; It is standard practice with many academic publishers to send faculty evaluation copies of textbooks upon request (and frequently without request, too!). I asked my department secretary to request an evaluation copy of Abbott’s book for me.&lt;/p&gt;

&lt;p&gt;The book arrived in my office mailbox in no time, and soon thereafter an invoice for $54.95 addressed to me personally arrived in my email with the comment, “60 DAY APPROVAL COPY, FREE WITH ADOPTION ONLY.” I forwarded the invoice to the secretary with the news that I had decided to adopt the textbook, and she communicated the news to the Springer rep listed on the invoice. All standard stuff.&lt;/p&gt;

&lt;p&gt;Then a couple of weeks later I got another copy of the same textbook in my mailbox. Oh, how funny! They accidentally sent me two. I gave it to the secretary. She rolls her eyes and says she’ll take care of it. She ships it back to Springer. Emails fly. The secretary forwarded one to me to inform me that it had been dealt with. The Springer rep was suitably embarrassed. He had written, “Can you believe we sent them a second book and then charged them for the first!” Someone at Springer would apparently take care of it for us.&lt;/p&gt;

&lt;p&gt;Then I get another invoice addressed to me personally. It must have gone out before the people at Springer took care of it. Right?&lt;/p&gt;

&lt;p&gt;Nope. Today I got a letter from a collections agency. Dr. Robert Jacobson owes $61. Springer literally sent me to a collections agency because I wanted to adopt their textbook for my course.&lt;/p&gt;</content><author><name>Robert Jacobson</name><email>rljacobson@gmail.com</email></author><category term="Education" /><category term="Academia" /><summary type="html">The story begins with one of those little mundane activities that fill every professor’s day. Right before the spring semester began I was evaluating various textbook options for the next time I teach undergraduate real analysis. Stephen Abbott’s Understanding Analysis published by Springer seemed to be exactly the kind of book I was looking for. It is standard practice with many academic publishers to send faculty evaluation copies of textbooks upon request (and frequently without request, too!). I asked my department secretary to request an evaluation copy of Abbott’s book for me.</summary></entry></feed>